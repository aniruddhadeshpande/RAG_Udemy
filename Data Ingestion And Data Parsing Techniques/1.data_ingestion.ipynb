{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f6b78f",
   "metadata": {},
   "source": [
    "### Introduction To Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb625da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/Projects/RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9576e49",
   "metadata": {},
   "source": [
    "### Understanding Document Structure In Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74d7238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document structure\n",
      "content: This is the main text content that will be embedded and searched.\n",
      "metadata: {'source': 'example.txt', 'author': 'Aniruddha', 'date': '2025-12-12', 'custom_field': 'custom_value'}\n"
     ]
    }
   ],
   "source": [
    "## Create a simple document\n",
    "doc = Document(\n",
    "    page_content=\"This is the main text content that will be embedded and searched.\",\n",
    "    metadata ={\n",
    "        \"source\":\"example.txt\",\n",
    "        \"author\":\"Aniruddha\",\n",
    "        \"date\":\"2025-12-12\",\n",
    "        \"custom_field\":\"custom_value\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Document structure\")\n",
    "print(f\"content: {doc.page_content}\")\n",
    "print(f\"metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b45dd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6837265",
   "metadata": {},
   "source": [
    "### TextLoader- Read Single File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0502cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Loaded 1 document\n",
      "First document content: Python Programming Introduction\n",
      "\n",
      "Python is a high-level, interpreted programming language known for ...\n",
      "First document metadata: {'source': 'data/text_files/python_intro.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "## Loading a single text file\n",
    "loader = TextLoader(\n",
    "    file_path=\"data/text_files/python_intro.txt\",\n",
    "    encoding=\"utf8\"\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"ðŸ“„ Loaded {len(documents)} document\")\n",
    "print(f\"First document content: {documents[0].page_content[:100]}...\")\n",
    "print(f\"First document metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ef77de",
   "metadata": {},
   "source": [
    "### DirectoryLoader- Multiple Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7deb859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 1663.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Loaded 2 documents\n",
      "\n",
      "Document 1:\n",
      "  Source: data/text_files/machine_learning.txt\n",
      "  Length: 575 characters\n",
      "\n",
      "Document 2:\n",
      "  Source: data/text_files/python_intro.txt\n",
      "  Length: 489 characters\n",
      "\n",
      "ðŸ“Š DirectoryLoader Characteristics:\n",
      "âœ… Advantages:\n",
      "  - Loads multiple files at once\n",
      "  - Supports glob patterns\n",
      "  - Progress tracking\n",
      "  - Recursive directory scanning\n",
      "\n",
      "âŒ Disadvantages:\n",
      "  - All files must be same type\n",
      "  - Limited error handling per file\n",
      "  - Can be memory intensive for large directories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "   \"data/text_files/\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\":\"utf8\"},\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "documents = dir_loader.load()\n",
    "print(f\"ðŸ“ Loaded {len(documents)} documents\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Source: {doc.metadata['source']}\")\n",
    "    print(f\"  Length: {len(doc.page_content)} characters\")\n",
    "\n",
    "\n",
    "# ðŸ“Š Analysis\n",
    "print(\"\\nðŸ“Š DirectoryLoader Characteristics:\")\n",
    "print(\"âœ… Advantages:\")\n",
    "print(\"  - Loads multiple files at once\")\n",
    "print(\"  - Supports glob patterns\")\n",
    "print(\"  - Progress tracking\")\n",
    "print(\"  - Recursive directory scanning\")\n",
    "\n",
    "print(\"\\nâŒ Disadvantages:\")\n",
    "print(\"  - All files must be same type\")\n",
    "print(\"  - Limited error handling per file\")\n",
    "print(\"  - Can be memory intensive for large directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4283600d",
   "metadata": {},
   "source": [
    "### Text Splitting Statergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5f46b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/text_files/machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '), Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26d4d9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ï¸âƒ£ CHARACTER TEXT SPLITTER\n",
      "Created chunks: 4\n",
      "First chunk: Machine Learning Basics\n",
      "Machine learning is a subset of artificial intelligence that enables systems...\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Character-based splitting\n",
    "\n",
    "print(\"1ï¸âƒ£ CHARACTER TEXT SPLITTER\")\n",
    "\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", # Split on newlines\n",
    "    chunk_size=200, # Max 200 characters per chunk\n",
    "    chunk_overlap=20, # 50 characters overlap\n",
    "    length_function=len # Use len() to measure text length\n",
    ")\n",
    "\n",
    "text=documents[0].page_content\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "print(f\"Created chunks: {len(char_chunks)}\")\n",
    "print(f\"First chunk: {char_chunks[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65ff0aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Basics\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "--------------------------------------------------\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "that can access data and use it to learn for themselves.\n",
      "Types of Machine Learning:\n"
     ]
    }
   ],
   "source": [
    "print(char_chunks[0])\n",
    "print(\"--------------------------------------------------\")\n",
    "print(char_chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2ï¸âƒ£ RECURSIVE CHARACTER TEXT SPLITTER\n",
      "Created chunks: 6\n",
      "First chunk: Machine Learning Basics...\n",
      "['Machine Learning Basics', 'Machine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs', 'that can access data and use it to learn for themselves.', 'Types of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data', '3. Reinforcement Learning: Learning through rewards and penalties', 'Applications include image recognition, speech processing, and recommendation systems']\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Recursive character splitting (RECOMMENDED)\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ RECURSIVE CHARACTER TEXT SPLITTER\")\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], # Hierarchical separators\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "### separators = [\"\\n\\n\", \"\\n\", \" \", \"\"], separators=[] # No splitting, return full text as one chunk, separators=None # Default separators\n",
    "\n",
    "chunks = recursive_splitter.split_text(text)\n",
    "print(f\"Created chunks: {len(chunks)}\")\n",
    "print(f\"First chunk: {chunks[0][:100]}...\")\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c921517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Basics\n",
      "--------------------------------------------------\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "--------------------------------------------------\n",
      "that can access data and use it to learn for themselves.\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])\n",
    "print(\"--------------------------------------------------\")\n",
    "print(chunks[1])\n",
    "print(\"--------------------------------------------------\")\n",
    "print(chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b81f406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3ï¸âƒ£ TOKEN TEXT SPLITTER\n",
      "Created chunks: 4\n",
      "First chunk: Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables system...\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Token-based splitting\n",
    "import token\n",
    "\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ TOKEN TEXT SPLITTER\")\n",
    "\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50, # Max 200 tokens per chunk\n",
    "    chunk_overlap=20, # 20 tokens overlap\n",
    "    encoding_name=\"gpt2\" # Use GPT-2 tokenizer\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "print(f\"Created chunks: {len(token_chunks)}\")\n",
    "print(f\"First chunk: {token_chunks[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f948bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "that can access data and use it to learn for themselves.\n",
      "\n",
      "Types\n",
      "--------------------------------------------------\n",
      " on developing computer programs\n",
      "that can access data and use it to learn for themselves.\n",
      "\n",
      "Types of Machine Learning:\n",
      "1. Supervised Learning: Learning with labeled data\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
      "--------------------------------------------------\n",
      ": Learning with labeled data\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
      "3. Reinforcement Learning: Learning through rewards and penalties\n",
      "\n",
      "Applications include image recognition, speech processing, and recommendation systems\n",
      "\n",
      "\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "print(token_chunks[0])\n",
    "print(\"--------------------------------------------------\")\n",
    "print(token_chunks[1])\n",
    "print(\"--------------------------------------------------\")\n",
    "print(token_chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "769b8b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Text Splitting Methods Comparison:\n",
      "\n",
      "CharacterTextSplitter:\n",
      "  âœ… Simple and predictable\n",
      "  âœ… Good for structured text\n",
      "  âŒ May break mid-sentence\n",
      "  Use when: Text has clear delimiters\n",
      "\n",
      "RecursiveCharacterTextSplitter:\n",
      "  âœ… Respects text structure\n",
      "  âœ… Tries multiple separators\n",
      "  âœ… Best general-purpose splitter\n",
      "  âŒ Slightly more complex\n",
      "  Use when: Default choice for most texts\n",
      "\n",
      "TokenTextSplitter:\n",
      "  âœ… Respects model token limits\n",
      "  âœ… More accurate for embeddings\n",
      "  âŒ Slower than character-based\n",
      "  Use when: Working with token-limited models\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Š Comparison\n",
    "print(\"\\nðŸ“Š Text Splitting Methods Comparison:\")\n",
    "print(\"\\nCharacterTextSplitter:\")\n",
    "print(\"  âœ… Simple and predictable\")\n",
    "print(\"  âœ… Good for structured text\")\n",
    "print(\"  âŒ May break mid-sentence\")\n",
    "print(\"  Use when: Text has clear delimiters\")\n",
    "\n",
    "print(\"\\nRecursiveCharacterTextSplitter:\")\n",
    "print(\"  âœ… Respects text structure\")\n",
    "print(\"  âœ… Tries multiple separators\")\n",
    "print(\"  âœ… Best general-purpose splitter\")\n",
    "print(\"  âŒ Slightly more complex\")\n",
    "print(\"  Use when: Default choice for most texts\")\n",
    "\n",
    "print(\"\\nTokenTextSplitter:\")\n",
    "print(\"  âœ… Respects model token limits\")\n",
    "print(\"  âœ… More accurate for embeddings\")\n",
    "print(\"  âŒ Slower than character-based\")\n",
    "print(\"  Use when: Working with token-limited models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
