{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf1694ed",
   "metadata": {},
   "source": [
    "#### Messages\n",
    "\n",
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM.\n",
    "Messages are objects that contain:\n",
    " - Role - Identifies the message type (e.g. system, user)\n",
    " - Content - Represents the actual content of the message (like text, images, audio, documents, etc.)\n",
    " - Metadata - Optional fields such as response information, message IDs, and token usage\n",
    "\n",
    "LangChain provides a standard message type that works across all model providers, ensuring consistent behavior regardless of the model being called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3783d0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/Projects/RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086dc4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "model = init_chat_model(\"openai:gpt-5-mini-2025-08-07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daeef59",
   "metadata": {},
   "source": [
    "### Text Prompts\n",
    "Text prompts are strings - ideal for straightforward generation tasks where you don’t need to retain conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082a121d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Short answer\\n- LangChain is an open-source framework for building applications that use large language models (LLMs). It provides high-level building blocks (prompt templates, chains/workflows, memory, agents, retrievers, and integrations with vector stores and external tools) so you can compose LLMs into reliable, production-ready apps (chatbots, RAG, agents, pipelines).\\n\\nWhat it gives you (key concepts)\\n- LLM wrappers: unified interface to call many model providers (OpenAI, Anthropic, Hugging Face, Azure, etc.).\\n- Prompt templates: reusable, parameterized prompts and prompt management.\\n- Chains: compose multiple LLM calls and logic into workflows (simple sequential chains, conditionals, etc.).\\n- Memory: state management for conversational agents (buffer, summarized memory, etc.).\\n- Tools & Agents: let an LLM call external tools (search, calculators, APIs, databases) and plan multi-step actions.\\n- Retrieval & RAG: document loaders, retrievers, and vectorstore integrations (FAISS, Chroma, Pinecone, Milvus, Weaviate, etc.) to do retrieval-augmented generation.\\n- Connectors: adapters for common data sources and services (databases, file systems, APIs).\\n- Utilities: caching, prompt evaluation, testing/evaluation helpers, and orchestration patterns.\\n\\nTypical uses\\n- Conversational assistants with context and memory\\n- Retrieval-augmented generation (answers grounded in your documents)\\n- Question answering over documents, PDFs, or databases\\n- Autonomous agents that call tools/APIs\\n- Pipelines that combine multiple model calls or actions\\n\\nSimple Python example\\n- Rough illustrative snippet:\\n  from langchain import OpenAI, LLMChain, PromptTemplate\\n  template = \"Write a short marketing blurb for a product that is a {product_type}.\"\\n  prompt = PromptTemplate(input_variables=[\"product_type\"], template=template)\\n  llm = OpenAI(temperature=0.7)\\n  chain = LLMChain(llm=llm, prompt=prompt)\\n  print(chain.run(product_type=\"wireless headphones\"))\\n\\nWhen to use LangChain\\n- Good if you need to orchestrate multiple LLM calls, keep conversational state, integrate retrieval/vector search, or build agentic behavior.\\n- If your needs are a single prompt to an LLM with no retrieval or orchestration, a direct API call may be simpler.\\n\\nEcosystem and resources\\n- LangChain has official SDKs (Python and JavaScript/TypeScript) and many community integrations. See the official docs and the GitHub repo for tutorials, example apps, and the full API reference.\\n\\nIf you want, I can:\\n- Show a full example for RAG (document ingestion + retrieval + chat).\\n- Walk through building an agent that calls a web search and a calculator.\\n- Compare LangChain to specific alternatives (LlamaIndex, Haystack).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1174, 'prompt_tokens': 11, 'total_tokens': 1185, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CtWD5lUP8Z8qOzC6gxKnEEziILG0I', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b7e24-a9c7-7740-b9a2-f53d56105ed4-0', usage_metadata={'input_tokens': 11, 'output_tokens': 1174, 'total_tokens': 1185, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 576}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What is LangChain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e0801",
   "metadata": {},
   "source": [
    "Use text prompts when:\n",
    "- You have a single, standalone request\n",
    "- You don’t need conversation history\n",
    "- You want minimal code complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc99f9",
   "metadata": {},
   "source": [
    "### Message Prompts\n",
    "Alternatively, you can pass in a list of messages to the model by providing a list of message objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4011a2fa",
   "metadata": {},
   "source": [
    "\n",
    "Message types\n",
    "- System message - Tells the model how to behave and provide context for interactions\n",
    "- Human message - Represents user input and interactions with the model\n",
    "- AI message - Responses generated by the model, including text content, tool calls, and metadata\n",
    "- Tool message - Represents the outputs of tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa26236b",
   "metadata": {},
   "source": [
    "### System Message\n",
    "A SystemMessage represent an initial set of instructions that primes the model’s behavior. You can use a system message to set the tone, define the model’s role, and establish guidelines for responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153aba8",
   "metadata": {},
   "source": [
    "\n",
    "### Human Message\n",
    "A HumanMessage represents user input and interactions. They can contain text, images, audio, files, and any other amount of multimodal content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed0cd83",
   "metadata": {},
   "source": [
    "### AI Message\n",
    "An AIMessage represents the output of a model invocation. They can include multimodal data, tool calls, and provider-specific metadata that you can later access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d81b6",
   "metadata": {},
   "source": [
    "### Tool Message\n",
    "For models that support tool calling, AI messages can contain tool calls. Tool messages are used to pass the results of a single tool execution back to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49812569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_tokens': 29, 'output_tokens': 2163, 'total_tokens': 2192, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 576}}\n",
      "Below are the practical differences between 4G (LTE-class) and 5G when applied to fighter aircraft communications and onboard networking, focused on operational capability, implementation constraints, and vulnerabilities. This is a high-level, non-actionable comparison intended to help planners and engineers decide where each technology fits in a tactical aviation context.\n",
      "\n",
      "High-level summary\n",
      "- 4G: Mature, well-understood, good for moderate-bandwidth services (voice, video, telemetry) and non-mission-critical data links. Easier to field but limited in latency, peak throughput, and deterministic behavior.\n",
      "- 5G: Higher throughput, much lower latency, support for deterministic/critical traffic (URLLC), network slicing, massive MIMO and beamforming, and tighter integration with edge compute and AI. Promises significant operational advantages—but requires careful hardening, integration, and spectrum/EMC/stealth trade-offs for fighter use.\n",
      "\n",
      "Side‑by‑side by key aspect\n",
      "\n",
      "- Latency and determinism\n",
      "  - 4G: Latency typically tens to hundreds of ms; not designed for deterministic, ultra-low-latency control loops.\n",
      "  - 5G: Targets single-digit to low double-digit ms (and sub-ms in ideal URLLC configurations) with mechanisms for deterministic behavior. Enables near-real-time sensor sharing, cooperative control primitives, and faster C2 cycles.\n",
      "\n",
      "- Throughput and capacity\n",
      "  - 4G: Best-effort Mbps to low-Gbps under ideal conditions; limited spectral efficiency.\n",
      "  - 5G: Much higher peak and sustained data rates (multi-Gbps per link in favorable spectrum), and higher aggregate capacity for many devices on a platform or in a formation.\n",
      "\n",
      "- Spectrum and RF technologies\n",
      "  - 4G: Typically operates in sub-6 GHz bands; robust under mobility and blockage; mature antenna and RF chain designs.\n",
      "  - 5G: Uses both sub-6 GHz and mmWave bands. mmWave provides very high throughput but suffers from shorter range, higher path loss, sensitivity to blockage, and more challenging aerodynamic/stealth and antenna positioning issues on fast-moving fighters.\n",
      "\n",
      "- Antenna, MIMO, and beamforming\n",
      "  - 4G: Limited MIMO capability relative to 5G; simpler antenna arrays.\n",
      "  - 5G: Massive MIMO and advanced beamforming enable spatial multiplexing and directed links (important for formation data links and high-capacity point-to-point comms), but require larger/embedded arrays, dynamic beam tracking at high speeds, and careful integration to preserve RCS/stealth.\n",
      "\n",
      "- Mobility and Doppler\n",
      "  - 4G: Designed for high-speed mobility but not extreme tactical speeds and maneuvers in contested environments.\n",
      "  - 5G: Newer physical-layer designs can better tolerate Doppler when optimized, but mmWave links and narrow beams make high-angle-rate maneuvers and beam tracking more challenging. Implementation must address high Doppler and fast handovers in air combat regimes.\n",
      "\n",
      "- Network architecture and functions\n",
      "  - 4G: Centralized EPC (core), relatively static slices of service types.\n",
      "  - 5G: Service-based architecture, disaggregated core, network slicing, edge compute (MEC). Enables segregated mission slices (e.g., secure URLLC slice for C2 and separate eMBB slice for ISR), localized processing to reduce latency, and on-platform/edge AI workflows.\n",
      "\n",
      "- Use cases enabled\n",
      "  - 4G: Comms to ground networks, non-real-time sensor offload, situational awareness updates, voice/video for logistics and support.\n",
      "  - 5G: High-definition sensor fusion sharing across platforms, cooperative engagement with minimal latency, distributed sensor/weapon coordination, offloading ML inference to edge nodes, large-scale UAV/manned-escort coordination.\n",
      "\n",
      "- Interoperability with tactical datalinks\n",
      "  - 4G: Can be used as a transport for non-critical datalinks and for gatewaying to civilian infrastructure.\n",
      "  - 5G: Can complement or augment tactical datalinks (Link 16, MADL, etc.) by providing high-bandwidth, low-latency channels and network slices, but it is not a direct drop-in replacement for hardened, anti-jam tactical waveforms without additional hardening.\n",
      "\n",
      "- Security and resilience\n",
      "  - 4G: Mature security model for commercial use; can be adapted and hardened but was not designed for contested EW environments.\n",
      "  - 5G: Improved authentication/cryptography and ability to isolate traffic via slices; however, the expanded attack surface (cloud/edge/core functions, virtualization, software-defined components) increases cyber and supply-chain risk unless rigorously controlled and militarized. Both need anti-jam, low-probability-of-intercept (LPI), and hardened implementations for military use.\n",
      "\n",
      "- Implementation and platform constraints (SWaP, EMC, stealth)\n",
      "  - 4G: Lower SWaP and integration complexity for legacy installations.\n",
      "  - 5G: Higher SWaP for the higher-bandwidth antennas and processing (especially for mmWave and massive MIMO); requires careful EMC and thermal management; antenna placement affects RCS and stealth—must be integrated into airframe design from the start or via carefully engineered conformal antennas.\n",
      "\n",
      "Operational implications and caveats\n",
      "- 5G offers operational leaps—near-real-time multi-platform sensor fusion, high-capacity datalinks for offboard processing, and network-sliced priority for mission-critical traffic—but only if implemented in a hardened, tactical manner (anti-jam waveforms, resilient control-plane, trusted supply chain).\n",
      "- mmWave 5G is excellent for short-range, high-bandwidth links (e.g., air-to-air datalinks in close formations or air-to-ground in permissive environments) but is fragile in contested, obstructed, or long-range scenarios; sub-6 GHz 5G modes are more robust but offer less peak capacity.\n",
      "- Commercial 5G stacks are not automatically suitable for mission-critical C2; virtualization and cloud-native elements must be hardened and vetted for EW and cyber threats.\n",
      "- High-speed flight dynamics (Doppler, rapid orientation changes) impose additional constraints on beamforming and handover algorithms—specialized PHY/MAC adaptations are needed for fighter-relevant performance.\n",
      "\n",
      "Recommendations for adoption\n",
      "- Treat 5G as an enabler and force-multiplier for ISR and distributed teaming, not as a straight replacement for hardened tactical waveforms. Use it to augment, offload, and provide flexible connectivity where appropriate.\n",
      "- Prioritize sub-6 GHz 5G modes for beyond-line-of-sight and high-mobility reliability; reserve mmWave for line-of-sight, high-capacity links inside formations or to high-altitude relays.\n",
      "- Design antenna systems and processing (MEC) into the platform early to manage SWaP, thermal, EMC, and stealth impacts.\n",
      "- Harden the control plane, implement rigorous supply-chain and software assurance, and build anti-jam/LPI features and fallback tactical waveforms into the architecture.\n",
      "- Validate 5G performance under realistic air combat maneuvers, Doppler, and contested-spectrum scenarios before relying on it for mission-critical functions.\n",
      "\n",
      "Bottom line\n",
      "5G brings much higher throughput, lower latency, network slicing and edge compute that can transform sensor-sharing and cooperative tactics for fighters. However, realizing those benefits in a fighter requires addressing mobility/Doppler, mmWave fragility, SWaP/stealth integration, cybersecurity, and EW hardening. In practice, a mixed approach (continue using proven tactical datalinks for critical functions, while adopting militarized 5G capabilities for high-bandwidth, low-latency, and edge-enabled missions) is the most practical near-term path.\n",
      "{'token_usage': {'completion_tokens': 2163, 'prompt_tokens': 29, 'total_tokens': 2192, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CtWMhiw1tAXDgoUOtiXtpl0CU2Jpz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage,AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are defence technology expert\"),\n",
    "    HumanMessage(\"Write difference between 4G and 5G technologies in fighter plane\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "print(response.usage_metadata)\n",
    "print(response.content)\n",
    "print(response.response_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495ea5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short answer: pick a web framework (I recommend FastAPI for new Python projects), design your resources and endpoints, implement handlers with validation and persistence, add tests and docs, secure and deploy. Below are concrete steps, a minimal example, and a slightly more production-ready pattern (DB + auth + tests).\n",
      "\n",
      "1) Key REST concepts (quick)\n",
      "- Resource-centric: /items, /users\n",
      "- HTTP verbs: GET (read), POST (create), PUT/PATCH (update), DELETE (delete)\n",
      "- Use proper status codes (200, 201, 204, 400, 401, 404, 422, 500)\n",
      "- Statelessness, idempotency (PUT idempotent), pagination/filtering, HATEOAS (optional)\n",
      "\n",
      "2) Recommended stack (Python)\n",
      "- FastAPI (validation, type hints, OpenAPI docs)\n",
      "- SQLAlchemy (ORM) or SQLModel\n",
      "- Alembic for migrations\n",
      "- Uvicorn/Gunicorn for serving\n",
      "- pytest + TestClient for tests\n",
      "- Docker for containerization\n",
      "\n",
      "3) Minimal example (no DB) — illustrates REST endpoints\n",
      "File: main.py\n",
      "```python\n",
      "from fastapi import FastAPI, HTTPException\n",
      "from pydantic import BaseModel\n",
      "from typing import Dict\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "class Item(BaseModel):\n",
      "    id: int | None = None\n",
      "    name: str\n",
      "    description: str | None = None\n",
      "\n",
      "# in-memory storage for demo\n",
      "db: Dict[int, Item] = {}\n",
      "next_id = 1\n",
      "\n",
      "@app.post(\"/items\", status_code=201)\n",
      "def create_item(item: Item):\n",
      "    global next_id\n",
      "    item.id = next_id\n",
      "    db[next_id] = item\n",
      "    next_id += 1\n",
      "    return item\n",
      "\n",
      "@app.get(\"/items\")\n",
      "def list_items():\n",
      "    return list(db.values())\n",
      "\n",
      "@app.get(\"/items/{item_id}\")\n",
      "def get_item(item_id: int):\n",
      "    item = db.get(item_id)\n",
      "    if not item:\n",
      "        raise HTTPException(status_code=404, detail=\"Item not found\")\n",
      "    return item\n",
      "\n",
      "@app.put(\"/items/{item_id}\")\n",
      "def update_item(item_id: int, updated: Item):\n",
      "    if item_id not in db:\n",
      "        raise HTTPException(status_code=404, detail=\"Item not found\")\n",
      "    updated.id = item_id\n",
      "    db[item_id] = updated\n",
      "    return updated\n",
      "\n",
      "@app.delete(\"/items/{item_id}\", status_code=204)\n",
      "def delete_item(item_id: int):\n",
      "    if item_id not in db:\n",
      "        raise HTTPException(status_code=404, detail=\"Item not found\")\n",
      "    del db[item_id]\n",
      "```\n",
      "Run: uvicorn main:app --reload\n",
      "Docs: http://127.0.0.1:8000/docs (auto generated OpenAPI UI)\n",
      "\n",
      "4) Production-ready pattern (FastAPI + SQLAlchemy)\n",
      "Project layout:\n",
      "- app/\n",
      "  - main.py\n",
      "  - models.py (SQLAlchemy)\n",
      "  - schemas.py (pydantic)\n",
      "  - crud.py\n",
      "  - database.py\n",
      "  - deps.py\n",
      "  - auth.py\n",
      "  - tests/\n",
      "\n",
      "Example snippets:\n",
      "\n",
      "database.py\n",
      "```python\n",
      "from sqlalchemy import create_engine\n",
      "from sqlalchemy.orm import sessionmaker, declarative_base\n",
      "\n",
      "SQLALCHEMY_DATABASE_URL = \"sqlite:///./test.db\"\n",
      "engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={\"check_same_thread\": False})\n",
      "SessionLocal = sessionmaker(bind=engine, autoflush=False, autocommit=False)\n",
      "Base = declarative_base()\n",
      "```\n",
      "\n",
      "models.py\n",
      "```python\n",
      "from sqlalchemy import Column, Integer, String\n",
      "from .database import Base\n",
      "\n",
      "class Item(Base):\n",
      "    __tablename__ = \"items\"\n",
      "    id = Column(Integer, primary_key=True, index=True)\n",
      "    name = Column(String, index=True)\n",
      "    description = Column(String, nullable=True)\n",
      "```\n",
      "\n",
      "schemas.py\n",
      "```python\n",
      "from pydantic import BaseModel\n",
      "\n",
      "class ItemCreate(BaseModel):\n",
      "    name: str\n",
      "    description: str | None = None\n",
      "\n",
      "class ItemRead(ItemCreate):\n",
      "    id: int\n",
      "\n",
      "    class Config:\n",
      "        orm_mode = True\n",
      "```\n",
      "\n",
      "crud.py\n",
      "```python\n",
      "from sqlalchemy.orm import Session\n",
      "from . import models, schemas\n",
      "\n",
      "def create_item(db: Session, item: schemas.ItemCreate):\n",
      "    db_item = models.Item(**item.dict())\n",
      "    db.add(db_item)\n",
      "    db.commit()\n",
      "    db.refresh(db_item)\n",
      "    return db_item\n",
      "\n",
      "def get_item(db: Session, item_id: int):\n",
      "    return db.query(models.Item).filter(models.Item.id == item_id).first()\n",
      "\n",
      "def list_items(db: Session, skip: int = 0, limit: int = 100):\n",
      "    return db.query(models.Item).offset(skip).limit(limit).all()\n",
      "```\n",
      "\n",
      "main.py (partial)\n",
      "```python\n",
      "from fastapi import Depends, FastAPI, HTTPException\n",
      "from sqlalchemy.orm import Session\n",
      "from . import crud, models, schemas, database\n",
      "\n",
      "models.Base.metadata.create_all(bind=database.engine)\n",
      "app = FastAPI()\n",
      "\n",
      "def get_db():\n",
      "    db = database.SessionLocal()\n",
      "    try:\n",
      "        yield db\n",
      "    finally:\n",
      "        db.close()\n",
      "\n",
      "@app.post(\"/items\", response_model=schemas.ItemRead, status_code=201)\n",
      "def create_item(item: schemas.ItemCreate, db: Session = Depends(get_db)):\n",
      "    return crud.create_item(db, item)\n",
      "\n",
      "@app.get(\"/items\", response_model=list[schemas.ItemRead])\n",
      "def read_items(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):\n",
      "    return crud.list_items(db, skip=skip, limit=limit)\n",
      "\n",
      "@app.get(\"/items/{item_id}\", response_model=schemas.ItemRead)\n",
      "def read_item(item_id: int, db: Session = Depends(get_db)):\n",
      "    db_item = crud.get_item(db, item_id)\n",
      "    if not db_item:\n",
      "        raise HTTPException(404, \"Not found\")\n",
      "    return db_item\n",
      "```\n",
      "\n",
      "5) Authentication (JWT/OAuth2)\n",
      "- Use OAuth2PasswordBearer from FastAPI and create JWTs. Protect endpoints with a dependency that verifies token and loads the current user.\n",
      "- Keep secret keys in environment variables / secret manager.\n",
      "\n",
      "6) Testing\n",
      "- Use pytest and fastapi.testclient.TestClient to write integration tests:\n",
      "```python\n",
      "from fastapi.testclient import TestClient\n",
      "from app.main import app\n",
      "\n",
      "client = TestClient(app)\n",
      "\n",
      "def test_create_and_get_item():\n",
      "    r = client.post(\"/items\", json={\"name\": \"apple\"})\n",
      "    assert r.status_code == 201\n",
      "    data = r.json()\n",
      "    item_id = data[\"id\"]\n",
      "\n",
      "    r2 = client.get(f\"/items/{item_id}\")\n",
      "    assert r2.status_code == 200\n",
      "    assert r2.json()[\"name\"] == \"apple\"\n",
      "```\n",
      "\n",
      "7) Deployment tips\n",
      "- Use Uvicorn with multiple workers behind a process manager: gunicorn -k uvicorn.workers.UvicornWorker\n",
      "- Use environment variables for config, secrets; use an RDBMS (Postgres) in production.\n",
      "- Add Alembic for DB migrations.\n",
      "- Containerize with Docker; add health checks; configure logging and metrics (Prometheus).\n",
      "- Serve HTTPS via reverse proxy (NGINX) or cloud platform managed TLS.\n",
      "\n",
      "8) Best-practices checklist\n",
      "- Input validation (pydantic)\n",
      "- Proper HTTP statuses and error messages\n",
      "- Pagination, filtering, sorting\n",
      "- Version your API (v1)\n",
      "- Rate limit & CORS\n",
      "- Authentication & authorization\n",
      "- Logging, metrics, health endpoints\n",
      "- Tests and CI/CD\n",
      "- Secure secrets and use HTTPS\n",
      "- Use OpenAPI docs for consumers\n",
      "\n",
      "If you want, I can:\n",
      "- Generate a complete starter repo (FastAPI + SQLAlchemy + Alembic + Dockerfile).\n",
      "- Show a JWT auth implementation.\n",
      "- Customize endpoints for a specific domain (e.g., users, products, blog). Which would you like next?\n"
     ]
    }
   ],
   "source": [
    "## Detailed info to the LLM through System message\n",
    "system_msg = SystemMessage(\"\"\"\n",
    "You are a senior Python developer with expertise in web frameworks.\n",
    "Always provide code examples and explain your reasoning.\n",
    "Be concise but thorough in your explanations.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6785d80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hi Alice — nice to meet you! How can I help today? (Questions, writing, code, planning, translations, troubleshooting, etc.)' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 10, 'total_tokens': 112, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CtWd19TIw8IDbJEnxKJ7ce2CIfP7O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b7e3d-3266-76a2-b17d-20cdf532fe6b-0' usage_metadata={'input_tokens': 10, 'output_tokens': 102, 'total_tokens': 112, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}\n",
      "{'token_usage': {'completion_tokens': 102, 'prompt_tokens': 10, 'total_tokens': 112, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CtWd19TIw8IDbJEnxKJ7ce2CIfP7O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "## Message Metadata\n",
    "human_msg = HumanMessage(\n",
    "    content=\"Hello!\",\n",
    "    name=\"alice\",  # Optional: identify different users\n",
    "    id=\"msg_123\",  # Optional: unique identifier for tracing\n",
    ")\n",
    "\n",
    "response_human_msg = model.invoke([human_msg])\n",
    "\n",
    "print(response_human_msg)\n",
    "print(response_human_msg.response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd5e26f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# Create an AI message manually (e.g., for conversation history)\n",
    "ai_msg = AIMessage(\"I'd be happy to help you with that question!\")\n",
    "\n",
    "# Add to conversation history\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Can you help me?\"),\n",
    "    ai_msg,  # Insert as if it came from the model\n",
    "    HumanMessage(\"Great! What's 2+2?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa6caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AIMessage, ToolMessage\n",
    "\n",
    "# After a model makes a tool call\n",
    "# (Here, we demonstrate manually creating the messages for brevity)\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"args\": {\"location\": \"San Francisco\"},\n",
    "        \"id\": \"call_123\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Execute tool and create result message\n",
    "weather_result = \"Sunny, 72°F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # Must match the call ID\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "messages = [\n",
    "    HumanMessage(\"What's the weather in San Francisco?\"),\n",
    "    ai_message,  # Model's tool call\n",
    "    tool_message,  # Tool execution result\n",
    "]\n",
    "response = model.invoke(messages)  # Model processes the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400acca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Sunny, 72°F', tool_call_id='call_123')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7ad14db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's currently sunny in San Francisco, 72°F (≈22°C). \\n\\nWould you like an hourly forecast, a 7-day outlook, or details like wind, humidity, or precipitation chance?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 241, 'prompt_tokens': 47, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CtX3OgGU31NLtXjRsw23I9dKmU1Rr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b7e56-25ca-7811-84cd-0ee8b8912725-0', usage_metadata={'input_tokens': 47, 'output_tokens': 241, 'total_tokens': 288, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
