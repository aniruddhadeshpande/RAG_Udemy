{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d1a19b",
   "metadata": {},
   "source": [
    "### Query Enhancement ‚Äì Query Expansion Techniques\n",
    "\n",
    "In a RAG pipeline, the quality of the query sent to the retriever determines how good the retrieved context is ‚Äî and therefore, how accurate the LLM‚Äôs final answer will be.\n",
    "\n",
    "That‚Äôs where Query Expansion / Enhancement comes in.\n",
    "\n",
    "#### üéØ What is Query Enhancement?\n",
    "Query enhancement refers to techniques used to improve or reformulate the user query to retrieve better, more relevant documents from the knowledge base.\n",
    "It is especially useful when:\n",
    "\n",
    "- The original query is short, ambiguous, or under-specified\n",
    "- You want to broaden the scope to catch synonyms, related phrases, or spelling variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "115b82ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableMap\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbcff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Load dataset\n",
    "loader = TextLoader(\"langchain_crewai_dataset.txt\")\n",
    "row_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee2b5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Use semantic chunk\n",
    "### Custom Semantic Chunker With Threshold\n",
    "\n",
    "class ThresholdSematicChunker:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\", threshold=0.7):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def split(self, text:str):\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        embeddings = self.model.encode(sentences)\n",
    "        chunks = []\n",
    "        current_chunk = [sentences[0]]\n",
    "\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim = cosine_similarity([embeddings[i - 1]], [embeddings[i]])[0][0]\n",
    "            if sim >= self.threshold:\n",
    "                current_chunk.append(sentences[i])\n",
    "            else:\n",
    "                chunks.append(\". \".join(current_chunk) + \".\")\n",
    "                current_chunk = [sentences[i]]\n",
    "\n",
    "        chunks.append(\". \".join(current_chunk) + \".\")\n",
    "        return chunks\n",
    "    \n",
    "    def split_document(self, docs):\n",
    "        result = []\n",
    "        for doc in docs:\n",
    "            for chunk in self.split(doc.page_content):\n",
    "                result.append(\n",
    "                    Document(\n",
    "                        page_content=chunk,\n",
    "                        metadata = doc.metadata\n",
    "                    )\n",
    "                )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce92c5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2.1: Split Documents\n",
    "\n",
    "semantic_chunker = ThresholdSematicChunker()\n",
    "\n",
    "semantic_chunk = semantic_chunker.split_document(row_docs)\n",
    "\n",
    "len(semantic_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ece0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Vector store\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "     model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "vector_store = FAISS.from_documents(\n",
    "    semantic_chunk,\n",
    "    embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c35bc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x72469a313b90>, search_type='mmr', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: MMR retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type = \"mmr\",\n",
    "    search_kwargs={\"k\":5}\n",
    ")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16d91fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={'max_input_tokens': 200000, 'max_output_tokens': 100000, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x724698fd73b0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x724698fd7470>, root_client=<openai.OpenAI object at 0x724698fd4530>, root_async_client=<openai.AsyncOpenAI object at 0x72469fbcc980>, model_name='o4-mini', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: LLM and Prompts\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm=init_chat_model(\"openai:o4-mini\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "872a600b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='\\nYou are a helpful assistant. Expand the following query to improve document retrieval by adding relevant synonyms, technical terms, and useful context.\\n\\nOriginal query: \"{query}\"\\n\\nExpanded query:\\n')\n",
       "| ChatOpenAI(profile={'max_input_tokens': 200000, 'max_output_tokens': 100000, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x724698fd73b0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x724698fd7470>, root_client=<openai.OpenAI object at 0x724698fd4530>, root_async_client=<openai.AsyncOpenAI object at 0x72469fbcc980>, model_name='o4-mini', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Query expansion\n",
    "\n",
    "query_expansion_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant. Expand the following query to improve document retrieval by adding relevant synonyms, technical terms, and useful context.\n",
    "\n",
    "Original query: \"{query}\"\n",
    "\n",
    "Expanded query:\n",
    "\"\"\")\n",
    "\n",
    "query_expansion_chain = query_expansion_prompt|llm|StrOutputParser()\n",
    "query_expansion_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd54651e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here‚Äôs one possible expanded query that adds synonyms, technical terms, and useful context around ‚ÄúLangchain memory‚Äù:\\n\\n‚ÄúLangChain memory‚Äù OR  \\n‚ÄúLangChain memory management‚Äù OR  \\n‚ÄúLangChain memory adapter‚Äù OR  \\n‚ÄúLangChain memory module‚Äù OR  \\n‚ÄúConversationBufferMemory‚Äù OR  \\n‚ÄúConversationSummaryMemory‚Äù OR  \\n‚ÄúMultiSessionMemory‚Äù OR  \\n‚Äúvector store memory‚Äù OR  \\n‚Äúembedding store‚Äù OR  \\n‚Äúpersistent memory‚Äù OR  \\n‚Äúsession memory‚Äù OR  \\n‚Äúchat memory‚Äù OR  \\n‚Äústate management‚Äù OR  \\n‚Äúcontextual memory‚Äù OR  \\n‚Äúmemory buffer‚Äù OR  \\n‚ÄúRAG‚Äù OR  \\n‚Äúretrieval-augmented generation‚Äù OR  \\n‚ÄúLLM memory‚Äù OR  \\n‚Äúcontext window‚Äù OR  \\n‚ÄúRedis adapter‚Äù OR  \\n‚ÄúMongoDB memory‚Äù OR  \\n‚ÄúLangChain Python‚Äù OR  \\n‚ÄúLangChain JavaScript‚Äù OR  \\n‚ÄúLangChain Java‚Äù'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion_chain.invoke(\n",
    "    {\n",
    "        \"query\":\"Langchain memory\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3be6c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: RAG answering prompt\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the question based on the context below.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm,\n",
    "    answer_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af7a0bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Full RAG pipeline with query expansion\n",
    "\n",
    "rag_pipeline = (\n",
    "    RunnableMap({\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"context\": lambda x: retriever.invoke(query_expansion_chain.invoke({\"query\": x[\"input\"]}))\n",
    "    })\n",
    "    | document_chain\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b702b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Answer:\n",
      " The excerpts provided don‚Äôt mention any specific memory model or memory types supported by CrewAI. No memory types are defined in the context you shared.\n"
     ]
    }
   ],
   "source": [
    "query = {\"input\": \"What types of memory does CrewAI support?\"}\n",
    "response = rag_pipeline.invoke(query)\n",
    "print(\"‚úÖ Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77da5a07",
   "metadata": {},
   "source": [
    "Question: \"What types of memory does LangChain support?\"\n",
    "‚úÖ Answer:\n",
    " LangChain supports at least two built-in memory types:  \n",
    "‚Ä¢ ConversationBufferMemory  \n",
    "‚Ä¢ ConversationSummaryMemory\n",
    "\n",
    "Question: What types of memory does LangGraph support?\n",
    "‚úÖ Answer:\n",
    " LangGraph currently supports two memory modules:  \n",
    "‚Ä¢ ConversationBufferMemory  \n",
    "‚Ä¢ ConversationSummaryMemory\n",
    "\n",
    "Question: What types of memory does CrewAI support?\n",
    "‚úÖ Answer:\n",
    " The excerpts provided don‚Äôt mention any specific memory model or memory types supported by CrewAI. No memory types are defined in the context you shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2eec0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded query:\n",
      "\n",
      "(\"CrewAI\" OR \"Crew AI\" OR \"digital crew agents\" OR \"virtual crew assistant\" OR \"AI-powered crew management\")  \n",
      "AND  \n",
      "(\"autonomous agent\" OR \"intelligent software agent\" OR \"multi-agent system\" OR \"agent-based model\" OR \"virtual assistant\")  \n",
      "AND  \n",
      "(\"crew scheduling\" OR \"crew coordination\" OR \"resource allocation\" OR \"team operations\" OR \"personnel planning\" OR \"crew resource management\")  \n",
      "AND  \n",
      "(\"machine learning\" OR \"deep learning\" OR \"reinforcement learning\" OR \"agent-based modeling\" OR \"decision support system\" OR \"automation\" OR \"digital twin\")\n",
      "‚úÖ Answer:\n",
      " CrewAI agents are LLM-powered, semi-autonomous ‚Äúcrew members‚Äù in a multi-agent orchestration framework.  Each agent is defined by:  \n",
      "‚Ä¢ A specific role (e.g. researcher, planner, executor)  \n",
      "‚Ä¢ A clear purpose and goal  \n",
      "‚Ä¢ A prescribed toolset it can invoke  \n",
      "\n",
      "Within the CrewAI framework, agents operate in parallel or in sequence‚Äîstaying on task and collaborating in a structured way‚Äîto ensure each contributes meaningfully to the overall objective and to enable both broader (horizontal) and deeper (vertical) scaling of reasoning.\n"
     ]
    }
   ],
   "source": [
    "# Step 8.1: Run query\n",
    "query = {\"input\": \"CrewAI agents?\"}\n",
    "print(query_expansion_chain.invoke({\"query\":query}))\n",
    "response = rag_pipeline.invoke(query)\n",
    "print(\"‚úÖ Answer:\\n\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
