{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571ef3e7",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and ChromaDB\n",
    "#### Introduction\n",
    "Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of large language models with external knowledge retrieval. This notebook will walk you through building a complete RAG system using:\n",
    "\n",
    "- LangChain: A framework for developing applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- OpenAI: For embeddings and language model (you can substitute with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "918795f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e2b8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "## langchain imports\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "#from langchain.schema  import Document\n",
    "\n",
    "## Vector Store imports\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import numpy\n",
    "\n",
    "# Utils imports\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b345ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAG (Retrieval-Augmented Generation) Architecture:\n",
      "\n",
      "1. Document Loading: Load documents from various sources\n",
      "2. Document Splitting: Break documents into smaller chunks\n",
      "3. Embedding Generation: Convert chunks into vector representations\n",
      "4. Vector Storage: Store embeddings in ChromaDB\n",
      "5. Query Processing: Convert user query to embedding\n",
      "6. Similarity Search: Find relevant chunks from vector store\n",
      "7. Context Augmentation: Combine retrieved chunks with query\n",
      "8. Response Generation: LLM generates answer using context\n",
      "\n",
      "Benefits of RAG:\n",
      "- Reduces hallucinations\n",
      "- Provides up-to-date information\n",
      "- Allows citing sources\n",
      "- Works with domain-specific knowledge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RAG Architecture Overview\n",
    "print(\"\"\"\n",
    "RAG (Retrieval-Augmented Generation) Architecture:\n",
    "\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "\n",
    "Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b082b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create sample documents\n",
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "191d67a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents saved to /tmp/tmpd8zxwm2s\n"
     ]
    }
   ],
   "source": [
    "## save sample documents to files\n",
    "\n",
    "import tempfile\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    with open(os.path.join(temp_dir, f\"doc_{i+1}.txt\"), \"w\") as f:\n",
    "        f.write(doc.strip())\n",
    "\n",
    "print(f\"Sample documents saved to {temp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7b206",
   "metadata": {},
   "source": [
    "### 2. Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ca75c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents.\n",
      "\n",
      "First document preview:\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "\n",
    "# Load documents from directory\n",
    "loader = DirectoryLoader(\n",
    "    temp_dir,\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf8\"},\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "print(f\"\\nFirst document preview:\")\n",
    "print(documents[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae7e77f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.'),\n",
       " Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_3.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_1.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6104eb",
   "metadata": {},
   "source": [
    "### Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bdeec92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 9 chunks from 3 documents\n",
      "Content of chunk 1: Deep Learning and Neural Networks...\n",
      "Metadata of chunk 1: {'source': '/tmp/tmpd8zxwm2s/doc_2.txt'}\n",
      "-----\n",
      "Content of chunk 2: Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "Metadata of chunk 2: {'source': '/tmp/tmpd8zxwm2s/doc_2.txt'}\n",
      "-----\n",
      "Content of chunk 3: processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
      "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
      "    excel at seq...\n",
      "Metadata of chunk 3: {'source': '/tmp/tmpd8zxwm2s/doc_2.txt'}\n",
      "-----\n",
      "Content of chunk 4: Natural Language Processing (NLP)...\n",
      "Metadata of chunk 4: {'source': '/tmp/tmpd8zxwm2s/doc_3.txt'}\n",
      "-----\n",
      "Content of chunk 5: NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
      "    machine...\n",
      "Metadata of chunk 5: {'source': '/tmp/tmpd8zxwm2s/doc_3.txt'}\n",
      "-----\n",
      "Content of chunk 6: architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
      "    context and relationships between words in text....\n",
      "Metadata of chunk 6: {'source': '/tmp/tmpd8zxwm2s/doc_3.txt'}\n",
      "-----\n",
      "Content of chunk 7: Machine Learning Fundamentals...\n",
      "Metadata of chunk 7: {'source': '/tmp/tmpd8zxwm2s/doc_1.txt'}\n",
      "-----\n",
      "Content of chunk 8: Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "Metadata of chunk 8: {'source': '/tmp/tmpd8zxwm2s/doc_1.txt'}\n",
      "-----\n",
      "Content of chunk 9: learning. Supervised learning uses labeled data to train models, while unsupervised \n",
      "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
      "    interaction with an envir...\n",
      "Metadata of chunk 9: {'source': '/tmp/tmpd8zxwm2s/doc_1.txt'}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Content of chunk {i+1}: {chunk.page_content[:200]}...\")\n",
    "    print(f\"Metadata of chunk {i+1}: {chunk.metadata}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1cf1b1",
   "metadata": {},
   "source": [
    "### Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1edc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5fe2c",
   "metadata": {},
   "source": [
    "### Intilialize the ChromaDB Vector Store And Stores the chunks in Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39958764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and persisted to disk.\n",
      "Number of vectors in store: 9\n"
     ]
    }
   ],
   "source": [
    "## Create a Chromdb vector store\n",
    "persistent_directory = \"./chroma_db_two\"\n",
    "\n",
    "## Initialize Chromadb with Open AI embeddings\n",
    "embedding_function = OpenAIEmbeddings(\n",
    "     model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=persistent_directory,\n",
    "    collection_name=\"rag_example\"\n",
    ")\n",
    "\n",
    "print(\"Vector store created and persisted to disk.\")\n",
    "print(f\"Number of vectors in store: {vector_store._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c637eb",
   "metadata": {},
   "source": [
    "### Test Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82259809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_1.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement'),\n",
       " Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_1.txt'}, page_content='Machine Learning Fundamentals')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the types of machine learning?\"\n",
    "similar_docs = vector_store.similarity_search(query, k=2)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3beaf22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_3.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       " Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_3.txt'}, page_content='NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is NLP?\"\n",
    "similar_docs = vector_store.similarity_search(query, k=2)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ccf22a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_2.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_2.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Deep Learning?\"\n",
    "similar_docs = vector_store.similarity_search(query, k=2)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cce7f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Deep Learning?\n",
      "\n",
      "Top similar documents retrieved: 2:\n",
      "\n",
      "Document 1 metadata:\n",
      "{'source': '/tmp/tmpd8zxwm2s/doc_2.txt'}\n",
      "\n",
      "Document 1 content:\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "Document 2 metadata:\n",
      "{'source': '/tmp/tmpd8zxwm2s/doc_2.txt'}\n",
      "\n",
      "Document 2 content:\n",
      "Deep learning is a subset of machine learning base\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Top similar documents retrieved: {len(similar_docs)}:\\n\")\n",
    "\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"Document {i+1} metadata:\\n{doc.metadata}\\n\")\n",
    "    print(f\"Document {i+1} content:\\n{doc.page_content[:50]}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed0ddd",
   "metadata": {},
   "source": [
    "### Advanced Similarity Search With Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a5abc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_2.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  0.5935789346694946),\n",
       " (Document(metadata={'source': '/tmp/tmpd8zxwm2s/doc_2.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language'),\n",
       "  0.6173093318939209)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_score = vector_store.similarity_search_with_score(query, k=2)\n",
    "results_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d220d",
   "metadata": {},
   "source": [
    "#### Understanding Similarity Scores\n",
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance metric used:\n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)\n",
    "- Score of 0 = identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "\n",
    "- Higher scores = MORE similar\n",
    "- Range: -1 to 1 (1 being identical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68662799",
   "metadata": {},
   "source": [
    "#### Initialize LLM, RAG Chain, Prompt Template,Query the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49eae7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Large Language Models (LLMs) are advanced artificial intelligence systems designed to understand, generate, and interpret human language. They are built using deep learning techniques, particularly neural networks with many layers, and are trained on vast amounts of textual data from books, articles, websites, and other sources. \\n\\nThese models learn statistical patterns and relationships within language, enabling them to perform a variety of tasks such as:\\n\\n- Text generation (e.g., writing essays, stories, or code)\\n- Language translation\\n- Summarization\\n- Question answering\\n- Sentiment analysis\\n\\nPopular examples of large language models include OpenAI's GPT series (like GPT-3 and GPT-4), Google's Bard, and Meta's LLaMA. Due to their size and extensive training data, they can produce coherent and contextually relevant responses, making them powerful tools for natural language understanding and automation.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 175, 'prompt_tokens': 13, 'total_tokens': 188, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7f8eb7d1f9', 'id': 'chatcmpl-CpvEJSiXf5qlVBUl6BiGEXqS5eI0r', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b4b0d-cecf-74d3-b592-3a999013cdc0-0', usage_metadata={'input_tokens': 13, 'output_tokens': 175, 'total_tokens': 188, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano-2025-04-14\")\n",
    "test_response = llm.invoke(\"What is Large Language Models?\")\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60356b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x751d916574d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x751d73702390>, root_client=<openai.OpenAI object at 0x751d73703cb0>, root_async_client=<openai.AsyncOpenAI object at 0x751d91656120>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generic model class\n",
    "\n",
    "from langchain.chat_models.base import init_chat_model\n",
    "llm = init_chat_model(\"openai:gpt-4.1\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "489ef20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Retrieval-Augmented Generation (RAG)** is an AI architecture that combines *retrieval* and *generation* to produce more informed and accurate responses, especially in tasks like open-domain question answering.\\n\\n### Core Concepts\\n\\n1. **Retriever:**  \\nRAG uses a retriever module (often based on dense vector search with models like DPR, or embeddings from BERT-like models) to fetch relevant documents/passages from a large external collection (knowledge base, Wikipedia, etc.) in response to the input query.\\n\\n2. **Generator:**  \\nA generator module (usually a sequence-to-sequence language model, like BART or T5) fuses the retrieved documents with the query to generate an answer or a response.\\n\\n### How RAG Works (Simplified Steps)\\n\\n1. **Query:**  \\nInput question or prompt is given.\\n\\n2. **Retrieve:**  \\nThe retriever searches a large corpus to find top-K most relevant passages based on semantic similarity to the query.\\n\\n3. **Augment:**  \\nThe retrieved passages are combined with the original question.\\n\\n4. **Generate:**  \\nThe generator produces an answer conditioned on both the query and the retrieved information.\\n\\n### Why Is RAG Useful?\\n\\n- **Better Factual Accuracy:** The model can reference up-to-date or external information instead of relying solely on what‚Äôs baked into its parameters.\\n- **Knowledge Scalability:** You can update or expand the knowledge base without retraining the model.\\n- **Explainability:** The retrieved documents can be shown as evidence, increasing trust and transparency.\\n\\n### Typical Applications\\n\\n- Open-domain question answering (e.g., answering questions about Wikipedia)\\n- Custom chatbots grounded on enterprise data\\n- Any scenario needing grounded and verifiable language generation\\n\\n### In Summary\\n\\n**RAG = Retrieval (search relevant info) + Augmented Generation (informed synthesis of an answer)**  \\nThis approach enables language models to access and use more information than what is stored just in their weights, leading to more accurate and up-to-date outputs.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 405, 'prompt_tokens': 22, 'total_tokens': 427, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_1a2c4a5ede', 'id': 'chatcmpl-CpvFGKCn5ly5fJ3N306dggjZcWQXb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b4b0e-b1fa-72d2-a819-ff67e6492ce4-0', usage_metadata={'input_tokens': 22, 'output_tokens': 405, 'total_tokens': 427, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Explain the concept of Retrieval-Augmented Generation (RAG) in AI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0151275d",
   "metadata": {},
   "source": [
    "### Modern RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "805dbc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5efde35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x751d91965970>, search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert vector store to retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "818ac179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create prompt template\n",
    "system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaacf1f",
   "metadata": {},
   "source": [
    "##### What is create_stuff_documents_chain?\n",
    "create_stuff_documents_chain creates a chain that \"stuffs\" (inserts) all retrieved documents into a single prompt and sends it to the LLM. It's called \"stuff\" because it literally stuffs all the documents into the context window at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5e8fc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x751d916574d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x751d73702390>, root_client=<openai.OpenAI object at 0x751d73703cb0>, root_async_client=<openai.AsyncOpenAI object at 0x751d91656120>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create a document chain\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fdc766",
   "metadata": {},
   "source": [
    "This chain:\n",
    "\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into the prompt's {context} placeholder\n",
    "- Sends the complete prompt to the LLM\n",
    "- Returns the LLM's response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23678779",
   "metadata": {},
   "source": [
    "#### What is create_retrieval_chain?\n",
    "create_retrieval_chain is a function that combines a retriever (which fetches relevant documents) with a document chain (which processes those documents with an LLM) to create a complete RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x74673469daf0>, search_kwargs={'k': 2}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x74672dddf0b0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x74672dd0ae10>, root_client=<openai.OpenAI object at 0x74672ddddfd0>, root_async_client=<openai.AsyncOpenAI object at 0x74672ddde690>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create The Final RAG Chain\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    document_chain\n",
    ")\n",
    "\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d0148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the types of machine learning?',\n",
       " 'context': [Document(metadata={'source': '/tmp/tmp8jfmezso/doc_1.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement'),\n",
       "  Document(metadata={'source': '/tmp/tmp8jfmezso/doc_1.txt'}, page_content='Machine Learning Fundamentals')],\n",
       " 'answer': 'The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, unsupervised learning finds patterns in unlabeled data, and reinforcement learning teaches agents to make decisions through trial and error. These categories cover the fundamental approaches to machine learning.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What are the types of machine learning?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82248ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, unsupervised learning finds patterns in unlabeled data, and reinforcement learning teaches agents to make decisions through trial and error. These categories cover the fundamental approaches to machine learning.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da398a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying RAG system with question: What are the three types of machine learning?\n",
      "--------------------------------------------------\n",
      "Answer: The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "\n",
      "--- Source 2 ---\n",
      "Machine Learning Fundamentals...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Querying RAG system with question: What is deep learning and how does it relate to neural networks?\n",
      "--------------------------------------------------\n",
      "Answer: Deep learning is a subset of machine learning that uses artificial neural networks with multiple layers to process complex data. Neural networks, inspired by the human brain, are the core architecture behind deep learning. Deep learning leverages these layered networks to achieve advanced performance in tasks like computer vision and natural language processing.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Querying RAG system with question: What are CNNs best used for?\n",
      "--------------------------------------------------\n",
      "Answer: CNNs (Convolutional Neural Networks) are best used for image processing tasks. They excel at recognizing spatial patterns, making them highly effective for image classification, object detection, and related applications. CNNs are widely used in computer vision tasks.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
      "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
      "    excel at seq...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to query the modern RAG system\n",
    "\n",
    "def query_rag_system(question: str):\n",
    "    print(f\"Querying RAG system with question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Using create_retrieval_chain approach\n",
    "    result = rag_chain.invoke({\"input\": question})\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(\"\\nRetrieved Context:\")\n",
    "    for i, doc in enumerate(result.get('context', [])):\n",
    "        print(f\"\\n--- Source {i+1} ---\")\n",
    "        print(doc.page_content[:200]+\"...\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Test queries\n",
    "test_questions = [\n",
    "    \"What are the three types of machine learning?\",\n",
    "    \"What is deep learning and how does it relate to neural networks?\",\n",
    "    \"What are CNNs best used for?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    query_rag_system(question)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a96df",
   "metadata": {},
   "source": [
    "Good ‚Äî this is **core ‚ÄúTraditional RAG‚Äù code**, and you already have all the prerequisites.\n",
    "I‚Äôll explain it **line by line**, but **concept-first**, not just syntax.\n",
    "\n",
    "I‚Äôll also **pause after each block** and ask you to confirm understanding (study-mode rule).\n",
    "\n",
    "---\n",
    "\n",
    "## 0Ô∏è‚É£ What problem this code solves (1-line summary)\n",
    "\n",
    "> It builds a **RAG pipeline** that:\n",
    ">\n",
    "> 1. retrieves relevant chunks from a vector store\n",
    "> 2. injects them into a prompt\n",
    "> 3. asks an LLM to answer using only that context\n",
    "\n",
    "Keep this pipeline in mind:\n",
    "\n",
    "```\n",
    "User Question ‚Üí Retriever ‚Üí Context ‚Üí Prompt ‚Üí LLM ‚Üí Answer\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Imports ‚Äî WHAT capabilities are we bringing in?\n",
    "\n",
    "```python\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "```\n",
    "\n",
    "### Conceptual meaning (important)\n",
    "\n",
    "| Import                         | What it represents                                     |\n",
    "| ------------------------------ | ------------------------------------------------------ |\n",
    "| `create_retrieval_chain`       | Orchestrator that connects **retrieval + generation**  |\n",
    "| `ChatPromptTemplate`           | Structured prompt (system + human messages)            |\n",
    "| `create_stuff_documents_chain` | Combines retrieved documents ‚Üí stuffs them into prompt |\n",
    "\n",
    "üìå **Key idea**\n",
    "LangChain already knows common RAG patterns ‚Äî these helpers **assemble the pipeline for you**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 1\n",
    "\n",
    "Can you tell me:\n",
    "\n",
    "> What two big steps does `create_retrieval_chain` connect?\n",
    "\n",
    "(Answer in one line before moving on.)\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Converting vector store ‚Üí retriever (VERY IMPORTANT)\n",
    "\n",
    "```python\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "```\n",
    "\n",
    "### What is happening conceptually?\n",
    "\n",
    "Your `vector_store` (Chroma, FAISS, etc.) **cannot be used directly** in RAG.\n",
    "\n",
    "LangChain expects a **Retriever interface**.\n",
    "\n",
    "So this line:\n",
    "\n",
    "```python\n",
    "vector_store.as_retriever()\n",
    "```\n",
    "\n",
    "wraps your vector store into something that can:\n",
    "\n",
    "* accept a **query**\n",
    "* return **relevant documents**\n",
    "\n",
    "---\n",
    "\n",
    "### Parameters explained\n",
    "\n",
    "#### `search_type=\"similarity\"`\n",
    "\n",
    "Means:\n",
    "\n",
    "> ‚ÄúUse vector similarity (cosine / L2) to find nearest chunks‚Äù\n",
    "\n",
    "Other options exist (later topics):\n",
    "\n",
    "* `mmr`\n",
    "* `similarity_score_threshold`\n",
    "\n",
    "---\n",
    "\n",
    "#### `search_kwargs={\"k\": 2}`\n",
    "\n",
    "Means:\n",
    "\n",
    "> ‚ÄúReturn top **2** most similar chunks‚Äù\n",
    "\n",
    "This directly affects:\n",
    "\n",
    "* context length\n",
    "* hallucination risk\n",
    "* answer quality\n",
    "\n",
    "üìå **RAG rule of thumb**\n",
    "More `k` ‚â† better answers\n",
    "It often adds noise.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 2\n",
    "\n",
    "If `k=2`, how many document chunks can the LLM *see* at maximum?\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Creating the SYSTEM PROMPT (the LLM‚Äôs behavior contract)\n",
    "\n",
    "```python\n",
    "system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "```\n",
    "\n",
    "### Why this is critical in RAG\n",
    "\n",
    "This prompt:\n",
    "\n",
    "* **binds the LLM to retrieved data**\n",
    "* explicitly discourages hallucination\n",
    "* limits verbosity\n",
    "\n",
    "The key placeholder:\n",
    "\n",
    "```text\n",
    "{context}\n",
    "```\n",
    "\n",
    "This is where retrieved chunks will be **injected automatically**.\n",
    "\n",
    "üìå Without `{context}`, this is **NOT RAG** ‚Äî it becomes plain prompting.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 3\n",
    "\n",
    "Why do we explicitly tell the LLM:\n",
    "\n",
    "> ‚ÄúIf you don‚Äôt know, say you don‚Äôt know‚Äù?\n",
    "\n",
    "(Think RAG failure modes.)\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ ChatPromptTemplate ‚Äî structuring messages\n",
    "\n",
    "```python\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "```\n",
    "\n",
    "### What this creates internally\n",
    "\n",
    "It builds a **chat-style prompt**:\n",
    "\n",
    "```\n",
    "System: instructions + context\n",
    "Human: user question\n",
    "```\n",
    "\n",
    "* `{input}` ‚Üí user‚Äôs query\n",
    "* `{context}` ‚Üí retrieved chunks (filled later)\n",
    "\n",
    "üìå This separation matters because:\n",
    "\n",
    "* system message controls behavior\n",
    "* human message contains the question\n",
    "\n",
    "---\n",
    "\n",
    "### Mental model\n",
    "\n",
    "This prompt does **NOT** execute yet.\n",
    "It‚Äôs just a **template** waiting for:\n",
    "\n",
    "* context\n",
    "* input\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 4\n",
    "\n",
    "At this point, does the prompt contain any retrieved data yet?\n",
    "(Yes / No ‚Äî and why?)\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ create_stuff_documents_chain ‚Äî stuffing context into the prompt\n",
    "\n",
    "```python\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "```\n",
    "\n",
    "### What ‚Äústuff‚Äù really means\n",
    "\n",
    "> Take **all retrieved documents**, concatenate them, and **stuff them into `{context}`**\n",
    "\n",
    "Internally:\n",
    "\n",
    "1. Retrieved docs ‚Üí list of `Document`\n",
    "2. Extract `page_content`\n",
    "3. Join them (usually with `\\n\\n`)\n",
    "4. Inject into `{context}`\n",
    "5. Send final prompt to LLM\n",
    "\n",
    "üìå This is the **generation half** of RAG.\n",
    "\n",
    "---\n",
    "\n",
    "### What this chain does NOT do\n",
    "\n",
    "‚ùå It does NOT retrieve documents\n",
    "‚ùå It does NOT embed queries\n",
    "\n",
    "It only:\n",
    "\n",
    "> ‚ÄúGiven documents + question ‚Üí produce answer‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 5\n",
    "\n",
    "Which component actually decides *which* documents are relevant:\n",
    "\n",
    "* retriever\n",
    "* document_chain\n",
    "* LLM\n",
    "\n",
    "(Only one is correct.)\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ create_retrieval_chain ‚Äî assembling full RAG\n",
    "\n",
    "```python\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    document_chain\n",
    ")\n",
    "```\n",
    "\n",
    "### This is the **final wiring step**\n",
    "\n",
    "Now the full pipeline exists:\n",
    "\n",
    "```\n",
    "User input\n",
    " ‚Üí retriever (vector search)\n",
    " ‚Üí document_chain (stuff context)\n",
    " ‚Üí LLM\n",
    " ‚Üí answer\n",
    "```\n",
    "\n",
    "You can think of `rag_chain` as:\n",
    "\n",
    "> A callable object that runs the **entire RAG flow**\n",
    "\n",
    "---\n",
    "\n",
    "### Why this abstraction is powerful\n",
    "\n",
    "* You don‚Äôt manually pass context\n",
    "* You don‚Äôt manually call retriever\n",
    "* You don‚Äôt manually format prompts\n",
    "\n",
    "Everything is orchestrated.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 6\n",
    "\n",
    "If you replace `llm` with GROQ or Gemini, does this chain break?\n",
    "(Why / why not?)\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Invoking the RAG chain (runtime execution)\n",
    "\n",
    "```python\n",
    "response = rag_chain.invoke({\"input\": \"What are the types of machine learning?\"})\n",
    "response\n",
    "```\n",
    "\n",
    "### What happens step-by-step (very important)\n",
    "\n",
    "1Ô∏è‚É£ `\"input\"` is embedded\n",
    "2Ô∏è‚É£ Retriever finds top-2 chunks\n",
    "3Ô∏è‚É£ Chunks ‚Üí `{context}`\n",
    "4Ô∏è‚É£ Prompt is formed\n",
    "5Ô∏è‚É£ LLM generates answer\n",
    "\n",
    "---\n",
    "\n",
    "### What `response` contains\n",
    "\n",
    "Usually:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"input\": \"...\",\n",
    "  \"context\": [Document, Document],\n",
    "  \"answer\": \"...\"\n",
    "}\n",
    "```\n",
    "\n",
    "This is **debug-friendly**:\n",
    "\n",
    "* you can inspect retrieved chunks\n",
    "* verify hallucinations\n",
    "* tune `k`\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Ultra-short recap (memorize this)\n",
    "\n",
    "* `as_retriever()` ‚Üí makes vector store usable\n",
    "* `ChatPromptTemplate` ‚Üí defines RAG prompt\n",
    "* `create_stuff_documents_chain` ‚Üí stuffs context\n",
    "* `create_retrieval_chain` ‚Üí full RAG pipeline\n",
    "* `.invoke()` ‚Üí executes everything\n",
    "\n",
    "---\n",
    "\n",
    "## Final question (answer before we proceed)\n",
    "\n",
    "üëâ **Why is this called ‚ÄúTraditional RAG‚Äù and not ‚ÄúConversational RAG‚Äù?**\n",
    "\n",
    "(One sentence is enough. This unlocks the next topic.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48608e2",
   "metadata": {},
   "source": [
    "### Create RAG Chain Alternative - Using LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables   import RunnablePassthrough, RunnableParallel\n",
    "from langchain_classic.prompts import ChatPromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395d488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question. \\nIf you don't know the answer based on the context, say you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a custom prompt\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\"\"Use the following context to answer the question. \n",
    "If you don't know the answer based on the context, say you don't know.\n",
    "Provide specific details from the context to support your answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\")\n",
    "custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54e94a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x751d91965970>, search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7164d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format the output documents for the prompt\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0e64b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The three types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. This is supported by the context, which states: \"There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement.\"'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_rcel = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_rcel.invoke(\"What are the three types of machine learning?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
