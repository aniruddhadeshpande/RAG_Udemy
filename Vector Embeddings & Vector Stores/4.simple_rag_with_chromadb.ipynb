{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571ef3e7",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and ChromaDB\n",
    "#### Introduction\n",
    "Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of large language models with external knowledge retrieval. This notebook will walk you through building a complete RAG system using:\n",
    "\n",
    "- LangChain: A framework for developing applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- OpenAI: For embeddings and language model (you can substitute with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "918795f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e2b8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "## langchain imports\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "## Vector Store imports\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import numpy\n",
    "\n",
    "# Utils imports\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b345ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAG (Retrieval-Augmented Generation) Architecture:\n",
      "\n",
      "1. Document Loading: Load documents from various sources\n",
      "2. Document Splitting: Break documents into smaller chunks\n",
      "3. Embedding Generation: Convert chunks into vector representations\n",
      "4. Vector Storage: Store embeddings in ChromaDB\n",
      "5. Query Processing: Convert user query to embedding\n",
      "6. Similarity Search: Find relevant chunks from vector store\n",
      "7. Context Augmentation: Combine retrieved chunks with query\n",
      "8. Response Generation: LLM generates answer using context\n",
      "\n",
      "Benefits of RAG:\n",
      "- Reduces hallucinations\n",
      "- Provides up-to-date information\n",
      "- Allows citing sources\n",
      "- Works with domain-specific knowledge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RAG Architecture Overview\n",
    "print(\"\"\"\n",
    "RAG (Retrieval-Augmented Generation) Architecture:\n",
    "\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "\n",
    "Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b082b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create sample documents\n",
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191d67a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents saved to /tmp/tmpr74h95rr\n"
     ]
    }
   ],
   "source": [
    "## save sample documents to files\n",
    "\n",
    "import tempfile\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    with open(os.path.join(temp_dir, f\"doc_{i+1}.txt\"), \"w\") as f:\n",
    "        f.write(doc.strip())\n",
    "\n",
    "print(f\"Sample documents saved to {temp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7b206",
   "metadata": {},
   "source": [
    "### 2. Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca75c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents.\n",
      "\n",
      "First document preview:\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of i...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "\n",
    "# Load documents from directory\n",
    "loader = DirectoryLoader(\n",
    "    temp_dir,\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf8\"},\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "print(f\"\\nFirst document preview:\")\n",
    "print(documents[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae7e77f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/tmp/tmpr74h95rr/doc_2.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_3.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_1.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6104eb",
   "metadata": {},
   "source": [
    "### Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bdeec92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 9 chunks from 3 documents\n",
      "Content of chunk 1: Deep Learning and Neural Networks...\n",
      "Metadata of chunk 1: {'source': '/tmp/tmpr74h95rr/doc_2.txt'}\n",
      "-----\n",
      "Content of chunk 2: Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "Metadata of chunk 2: {'source': '/tmp/tmpr74h95rr/doc_2.txt'}\n",
      "-----\n",
      "Content of chunk 3: processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
      "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
      "    excel at seq...\n",
      "Metadata of chunk 3: {'source': '/tmp/tmpr74h95rr/doc_2.txt'}\n",
      "-----\n",
      "Content of chunk 4: Natural Language Processing (NLP)...\n",
      "Metadata of chunk 4: {'source': '/tmp/tmpr74h95rr/doc_3.txt'}\n",
      "-----\n",
      "Content of chunk 5: NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
      "    machine...\n",
      "Metadata of chunk 5: {'source': '/tmp/tmpr74h95rr/doc_3.txt'}\n",
      "-----\n",
      "Content of chunk 6: architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
      "    context and relationships between words in text....\n",
      "Metadata of chunk 6: {'source': '/tmp/tmpr74h95rr/doc_3.txt'}\n",
      "-----\n",
      "Content of chunk 7: Machine Learning Fundamentals...\n",
      "Metadata of chunk 7: {'source': '/tmp/tmpr74h95rr/doc_1.txt'}\n",
      "-----\n",
      "Content of chunk 8: Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "Metadata of chunk 8: {'source': '/tmp/tmpr74h95rr/doc_1.txt'}\n",
      "-----\n",
      "Content of chunk 9: learning. Supervised learning uses labeled data to train models, while unsupervised \n",
      "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
      "    interaction with an envir...\n",
      "Metadata of chunk 9: {'source': '/tmp/tmpr74h95rr/doc_1.txt'}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Content of chunk {i+1}: {chunk.page_content[:200]}...\")\n",
    "    print(f\"Metadata of chunk {i+1}: {chunk.metadata}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1cf1b1",
   "metadata": {},
   "source": [
    "### Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1edc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5fe2c",
   "metadata": {},
   "source": [
    "### Intilialize the ChromaDB Vector Store And Stores the chunks in Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39958764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and persisted to disk.\n",
      "Number of vectors in store: 9\n"
     ]
    }
   ],
   "source": [
    "## Create a Chromdb vector store\n",
    "persistent_directory = \"./chroma_db_three\"\n",
    "\n",
    "## Initialize Chromadb with Open AI embeddings\n",
    "embedding_function = OpenAIEmbeddings(\n",
    "     model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=persistent_directory,\n",
    "    collection_name=\"rag_example\"\n",
    ")\n",
    "\n",
    "print(\"Vector store created and persisted to disk.\")\n",
    "print(f\"Number of vectors in store: {vector_store._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c637eb",
   "metadata": {},
   "source": [
    "### Test Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82259809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/tmp/tmpr74h95rr/doc_1.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_1.txt'}, page_content='Machine Learning Fundamentals')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the types of machine learning?\"\n",
    "similar_docs = vector_store.similarity_search(query, k=2)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3beaf22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/tmp/tmpr74h95rr/doc_3.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_3.txt'}, page_content='NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is NLP?\"\n",
    "similar_docs = vector_store.similarity_search(query, k=2)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ccf22a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/tmp/tmpr74h95rr/doc_2.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_2.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Deep Learning?\"\n",
    "similar_docs = vector_store.similarity_search(query, k=2)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cce7f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Deep Learning?\n",
      "\n",
      "Top similar documents retrieved: 2:\n",
      "\n",
      "Document 1 metadata:\n",
      "{'source': '/tmp/tmpr74h95rr/doc_2.txt'}\n",
      "\n",
      "Document 1 content:\n",
      "Deep Learning and Neural Networks\n",
      "\n",
      "Document 2 metadata:\n",
      "{'source': '/tmp/tmpr74h95rr/doc_2.txt'}\n",
      "\n",
      "Document 2 content:\n",
      "Deep learning is a subset of machine learning base\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Top similar documents retrieved: {len(similar_docs)}:\\n\")\n",
    "\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"Document {i+1} metadata:\\n{doc.metadata}\\n\")\n",
    "    print(f\"Document {i+1} content:\\n{doc.page_content[:50]}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed0ddd",
   "metadata": {},
   "source": [
    "### Advanced Similarity Search With Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a5abc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': '/tmp/tmpr74h95rr/doc_2.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  0.5936423540115356),\n",
       " (Document(metadata={'source': '/tmp/tmpr74h95rr/doc_2.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language'),\n",
       "  0.6174697875976562)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_score = vector_store.similarity_search_with_score(query, k=2)\n",
    "results_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d220d",
   "metadata": {},
   "source": [
    "#### Understanding Similarity Scores\n",
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance metric used:\n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)\n",
    "- Score of 0 = identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "\n",
    "- Higher scores = MORE similar\n",
    "- Range: -1 to 1 (1 being identical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68662799",
   "metadata": {},
   "source": [
    "#### Initialize LLM, RAG Chain, Prompt Template,Query the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49eae7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Large Language Models (LLMs) are advanced artificial intelligence systems designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to recognize patterns, grasp context, and produce coherent and contextually appropriate responses. Examples of LLMs include OpenAI's GPT series (like GPT-3 and GPT-4), Google's BERT, and others.\\n\\nKey features of Large Language Models include:\\n\\n- **Scale:** They involve billions or even trillions of parameters, which are the adjustable parts of the model that learn from data.\\n- **Training Data:** LLMs are trained on diverse and extensive datasets encompassing books, articles, websites, and other text resources.\\n- **Capabilities:** They can perform various tasks such as answering questions, translating languages, summarizing texts, generating creative writing, and more.\\n- **Understanding Context:** Due to their size and training, they can often grasp nuanced meaning, idioms, and complex language structures.\\n- **Limitations:** Despite their capabilities, LLMs may generate plausible but incorrect information, lack true understanding, and sometimes produce biased or inappropriate outputs.\\n\\nOverall, Large Language Models are powerful tools that significantly advance natural language processing, enabling a wide range of applications across industries.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 248, 'prompt_tokens': 13, 'total_tokens': 261, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7f8eb7d1f9', 'id': 'chatcmpl-CqrRXghLpsHpSmxcJSK7e5kgiAkYT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5864-4b68-7e60-9a8c-4c08eca180f9-0', usage_metadata={'input_tokens': 13, 'output_tokens': 248, 'total_tokens': 261, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano-2025-04-14\")\n",
    "test_response = llm.invoke(\"What is Large Language Models?\")\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60356b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x7cbd75b1dbb0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7cbd75b1d1c0>, root_client=<openai.OpenAI object at 0x7cbd75b1d8b0>, root_async_client=<openai.AsyncOpenAI object at 0x7cbd75b1d640>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generic model class\n",
    "\n",
    "from langchain.chat_models.base import init_chat_model\n",
    "llm = init_chat_model(\"openai:gpt-4.1\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "489ef20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Retrieval-Augmented Generation (RAG)** is an advanced method in artificial intelligence and natural language processing that combines two main components: information retrieval and text generation. Its goal is to improve the accuracy and factuality of AI-generated responses by allowing the model to access and use external data sources during generation.\\n\\n### Key Concepts:\\n\\n1. **Retrieval**\\n   - When answering a user query, RAG first retrieves relevant documents or passages from a large external database (such as Wikipedia, company knowledge bases, or other text collections).\\n   - This retrieval step is usually done using a separate **retriever** model, which finds the most relevant context pieces based on the query.\\n\\n2. **Generation**\\n   - Next, a **generator** model (often a language model like GPT or BART) takes the retrieved information and generates a coherent and contextually appropriate answer.\\n   - The generator can cite, summarize, or synthesize information from the retrieved documents, making its response more accurate and up-to-date.\\n\\n### Why Use RAG?\\n\\n- **Up-to-date Knowledge:** The model isn\\'t limited to information seen during its training. By retrieving documents at runtime, it can provide more current or specific answers.\\n- **Improved Factuality:** Responses are grounded in actual documents, reducing the risk of hallucination (making up facts).\\n- **Scalability:** It can access vast amounts of information without needing to memorize it all in neural network weights.\\n\\n### How RAG Works (Overview):\\n\\n1. **Input:** User provides a query (e.g., \"What is Retrieval-Augmented Generation?\").\\n2. **Retrieval:** The retriever finds several relevant documents from a data corpus.\\n3. **Augmentation:** The generator processes both the query and retrieved texts.\\n4. **Generation:** The generator outputs an answer that may reference or quote the retrieved documents.\\n\\n### Example\\n\\nSuppose you ask, \"Who wrote \\'Pride and Prejudice\\'?\"  \\n- **Retriever:** Finds Wikipedia articles mentioning \\'Pride and Prejudice\\' and Jane Austen.\\n- **Generator:** Reads these passages and answers, \"Jane Austen wrote \\'Pride and Prejudice.\\'\"\\n\\n### Summary Table\\n\\n| Component    | Purpose                                                                 |\\n|--------------|------------------------------------------------------------------------|\\n| Retriever    | Finds relevant information from external database or documents          |\\n| Generator    | Produces human-like answers, referencing the retrieved information      |\\n\\n### Use Cases\\n\\n- Customer support chatbots\\n- Medical question answering\\n- Educational tools\\n- Search engines with natural language interfaces\\n\\n---\\n\\n**In summary:**  \\nRetrieval-Augmented Generation (RAG) enhances language models by letting them fetch and use external information dynamically, resulting in more accurate and informed AI responses.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 545, 'prompt_tokens': 22, 'total_tokens': 567, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_1a2c4a5ede', 'id': 'chatcmpl-CqrRyDsrVhVa4U4BwgHBV8KECl4iQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5864-b3f5-7581-944f-8c253985c155-0', usage_metadata={'input_tokens': 22, 'output_tokens': 545, 'total_tokens': 567, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Explain the concept of Retrieval-Augmented Generation (RAG) in AI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0151275d",
   "metadata": {},
   "source": [
    "### Modern RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "805dbc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5efde35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7cbd7a2117f0>, search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert vector store to retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "818ac179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create prompt template\n",
    "system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaacf1f",
   "metadata": {},
   "source": [
    "##### What is create_stuff_documents_chain?\n",
    "create_stuff_documents_chain creates a chain that \"stuffs\" (inserts) all retrieved documents into a single prompt and sends it to the LLM. It's called \"stuff\" because it literally stuffs all the documents into the context window at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5e8fc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x7cbd75b1dbb0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7cbd75b1d1c0>, root_client=<openai.OpenAI object at 0x7cbd75b1d8b0>, root_async_client=<openai.AsyncOpenAI object at 0x7cbd75b1d640>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create a document chain\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fdc766",
   "metadata": {},
   "source": [
    "This chain:\n",
    "\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into the prompt's {context} placeholder\n",
    "- Sends the complete prompt to the LLM\n",
    "- Returns the LLM's response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23678779",
   "metadata": {},
   "source": [
    "#### What is create_retrieval_chain?\n",
    "create_retrieval_chain is a function that combines a retriever (which fetches relevant documents) with a document chain (which processes those documents with an LLM) to create a complete RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8b3554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7cbd7a2117f0>, search_kwargs={'k': 2}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x7cbd75b1dbb0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7cbd75b1d1c0>, root_client=<openai.OpenAI object at 0x7cbd75b1d8b0>, root_async_client=<openai.AsyncOpenAI object at 0x7cbd75b1d640>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create The Final RAG Chain\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    document_chain\n",
    ")\n",
    "\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae4d0148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the types of machine learning?',\n",
       " 'context': [Document(metadata={'source': '/tmp/tmpr74h95rr/doc_1.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement'),\n",
       "  Document(metadata={'source': '/tmp/tmpr74h95rr/doc_1.txt'}, page_content='Machine Learning Fundamentals')],\n",
       " 'answer': 'The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, unsupervised learning finds patterns in unlabeled data, and reinforcement learning enables systems to learn through rewards and penalties. These approaches allow systems to learn and improve from experience without explicit programming.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What are the types of machine learning?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82248ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data to train models, unsupervised learning finds patterns in unlabeled data, and reinforcement learning enables systems to learn through rewards and penalties. These approaches allow systems to learn and improve from experience without explicit programming.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4da398a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying RAG system with question: What are the three types of machine learning?\n",
      "--------------------------------------------------\n",
      "Answer: The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "\n",
      "--- Source 2 ---\n",
      "Machine Learning Fundamentals...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Querying RAG system with question: What is deep learning and how does it relate to neural networks?\n",
      "--------------------------------------------------\n",
      "Answer: Deep learning is a subset of machine learning that uses artificial neural networks inspired by the human brain. These networks are composed of layers of interconnected nodes (neurons) that process data hierarchically. Deep learning relies on neural networks with multiple layers (deep neural networks) to learn complex patterns from large datasets.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Querying RAG system with question: What are CNNs best used for?\n",
      "--------------------------------------------------\n",
      "Answer: CNNs (Convolutional Neural Networks) are best used for image processing tasks. They excel at recognizing patterns, features, and objects within visual data. Their architecture makes them highly effective for applications such as image classification, object detection, and facial recognition.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
      "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
      "    excel at seq...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to query the modern RAG system\n",
    "\n",
    "def query_rag_system(question: str):\n",
    "    print(f\"Querying RAG system with question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Using create_retrieval_chain approach\n",
    "    result = rag_chain.invoke({\"input\": question})\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(\"\\nRetrieved Context:\")\n",
    "    for i, doc in enumerate(result.get('context', [])):\n",
    "        print(f\"\\n--- Source {i+1} ---\")\n",
    "        print(doc.page_content[:200]+\"...\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Test queries\n",
    "test_questions = [\n",
    "    \"What are the three types of machine learning?\",\n",
    "    \"What is deep learning and how does it relate to neural networks?\",\n",
    "    \"What are CNNs best used for?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    query_rag_system(question)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a96df",
   "metadata": {},
   "source": [
    "Good ‚Äî this is **core ‚ÄúTraditional RAG‚Äù code**, and you already have all the prerequisites.\n",
    "I‚Äôll explain it **line by line**, but **concept-first**, not just syntax.\n",
    "\n",
    "I‚Äôll also **pause after each block** and ask you to confirm understanding (study-mode rule).\n",
    "\n",
    "---\n",
    "\n",
    "## 0Ô∏è‚É£ What problem this code solves (1-line summary)\n",
    "\n",
    "> It builds a **RAG pipeline** that:\n",
    ">\n",
    "> 1. retrieves relevant chunks from a vector store\n",
    "> 2. injects them into a prompt\n",
    "> 3. asks an LLM to answer using only that context\n",
    "\n",
    "Keep this pipeline in mind:\n",
    "\n",
    "```\n",
    "User Question ‚Üí Retriever ‚Üí Context ‚Üí Prompt ‚Üí LLM ‚Üí Answer\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Imports ‚Äî WHAT capabilities are we bringing in?\n",
    "\n",
    "```python\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "```\n",
    "\n",
    "### Conceptual meaning (important)\n",
    "\n",
    "| Import                         | What it represents                                     |\n",
    "| ------------------------------ | ------------------------------------------------------ |\n",
    "| `create_retrieval_chain`       | Orchestrator that connects **retrieval + generation**  |\n",
    "| `ChatPromptTemplate`           | Structured prompt (system + human messages)            |\n",
    "| `create_stuff_documents_chain` | Combines retrieved documents ‚Üí stuffs them into prompt |\n",
    "\n",
    "üìå **Key idea**\n",
    "LangChain already knows common RAG patterns ‚Äî these helpers **assemble the pipeline for you**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 1\n",
    "\n",
    "Can you tell me:\n",
    "\n",
    "> What two big steps does `create_retrieval_chain` connect?\n",
    "\n",
    "(Answer in one line before moving on.)\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Converting vector store ‚Üí retriever (VERY IMPORTANT)\n",
    "\n",
    "```python\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "```\n",
    "\n",
    "### What is happening conceptually?\n",
    "\n",
    "Your `vector_store` (Chroma, FAISS, etc.) **cannot be used directly** in RAG.\n",
    "\n",
    "LangChain expects a **Retriever interface**.\n",
    "\n",
    "So this line:\n",
    "\n",
    "```python\n",
    "vector_store.as_retriever()\n",
    "```\n",
    "\n",
    "wraps your vector store into something that can:\n",
    "\n",
    "* accept a **query**\n",
    "* return **relevant documents**\n",
    "\n",
    "---\n",
    "\n",
    "### Parameters explained\n",
    "\n",
    "#### `search_type=\"similarity\"`\n",
    "\n",
    "Means:\n",
    "\n",
    "> ‚ÄúUse vector similarity (cosine / L2) to find nearest chunks‚Äù\n",
    "\n",
    "Other options exist (later topics):\n",
    "\n",
    "* `mmr`\n",
    "* `similarity_score_threshold`\n",
    "\n",
    "---\n",
    "\n",
    "#### `search_kwargs={\"k\": 2}`\n",
    "\n",
    "Means:\n",
    "\n",
    "> ‚ÄúReturn top **2** most similar chunks‚Äù\n",
    "\n",
    "This directly affects:\n",
    "\n",
    "* context length\n",
    "* hallucination risk\n",
    "* answer quality\n",
    "\n",
    "üìå **RAG rule of thumb**\n",
    "More `k` ‚â† better answers\n",
    "It often adds noise.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 2\n",
    "\n",
    "If `k=2`, how many document chunks can the LLM *see* at maximum?\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Creating the SYSTEM PROMPT (the LLM‚Äôs behavior contract)\n",
    "\n",
    "```python\n",
    "system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "```\n",
    "\n",
    "### Why this is critical in RAG\n",
    "\n",
    "This prompt:\n",
    "\n",
    "* **binds the LLM to retrieved data**\n",
    "* explicitly discourages hallucination\n",
    "* limits verbosity\n",
    "\n",
    "The key placeholder:\n",
    "\n",
    "```text\n",
    "{context}\n",
    "```\n",
    "\n",
    "This is where retrieved chunks will be **injected automatically**.\n",
    "\n",
    "üìå Without `{context}`, this is **NOT RAG** ‚Äî it becomes plain prompting.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 3\n",
    "\n",
    "Why do we explicitly tell the LLM:\n",
    "\n",
    "> ‚ÄúIf you don‚Äôt know, say you don‚Äôt know‚Äù?\n",
    "\n",
    "(Think RAG failure modes.)\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ ChatPromptTemplate ‚Äî structuring messages\n",
    "\n",
    "```python\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "```\n",
    "\n",
    "### What this creates internally\n",
    "\n",
    "It builds a **chat-style prompt**:\n",
    "\n",
    "```\n",
    "System: instructions + context\n",
    "Human: user question\n",
    "```\n",
    "\n",
    "* `{input}` ‚Üí user‚Äôs query\n",
    "* `{context}` ‚Üí retrieved chunks (filled later)\n",
    "\n",
    "üìå This separation matters because:\n",
    "\n",
    "* system message controls behavior\n",
    "* human message contains the question\n",
    "\n",
    "---\n",
    "\n",
    "### Mental model\n",
    "\n",
    "This prompt does **NOT** execute yet.\n",
    "It‚Äôs just a **template** waiting for:\n",
    "\n",
    "* context\n",
    "* input\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 4\n",
    "\n",
    "At this point, does the prompt contain any retrieved data yet?\n",
    "(Yes / No ‚Äî and why?)\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ create_stuff_documents_chain ‚Äî stuffing context into the prompt\n",
    "\n",
    "```python\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "```\n",
    "\n",
    "### What ‚Äústuff‚Äù really means\n",
    "\n",
    "> Take **all retrieved documents**, concatenate them, and **stuff them into `{context}`**\n",
    "\n",
    "Internally:\n",
    "\n",
    "1. Retrieved docs ‚Üí list of `Document`\n",
    "2. Extract `page_content`\n",
    "3. Join them (usually with `\\n\\n`)\n",
    "4. Inject into `{context}`\n",
    "5. Send final prompt to LLM\n",
    "\n",
    "üìå This is the **generation half** of RAG.\n",
    "\n",
    "---\n",
    "\n",
    "### What this chain does NOT do\n",
    "\n",
    "‚ùå It does NOT retrieve documents\n",
    "‚ùå It does NOT embed queries\n",
    "\n",
    "It only:\n",
    "\n",
    "> ‚ÄúGiven documents + question ‚Üí produce answer‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 5\n",
    "\n",
    "Which component actually decides *which* documents are relevant:\n",
    "\n",
    "* retriever\n",
    "* document_chain\n",
    "* LLM\n",
    "\n",
    "(Only one is correct.)\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ create_retrieval_chain ‚Äî assembling full RAG\n",
    "\n",
    "```python\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    document_chain\n",
    ")\n",
    "```\n",
    "\n",
    "### This is the **final wiring step**\n",
    "\n",
    "Now the full pipeline exists:\n",
    "\n",
    "```\n",
    "User input\n",
    " ‚Üí retriever (vector search)\n",
    " ‚Üí document_chain (stuff context)\n",
    " ‚Üí LLM\n",
    " ‚Üí answer\n",
    "```\n",
    "\n",
    "You can think of `rag_chain` as:\n",
    "\n",
    "> A callable object that runs the **entire RAG flow**\n",
    "\n",
    "---\n",
    "\n",
    "### Why this abstraction is powerful\n",
    "\n",
    "* You don‚Äôt manually pass context\n",
    "* You don‚Äôt manually call retriever\n",
    "* You don‚Äôt manually format prompts\n",
    "\n",
    "Everything is orchestrated.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checkpoint 6\n",
    "\n",
    "If you replace `llm` with GROQ or Gemini, does this chain break?\n",
    "(Why / why not?)\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Invoking the RAG chain (runtime execution)\n",
    "\n",
    "```python\n",
    "response = rag_chain.invoke({\"input\": \"What are the types of machine learning?\"})\n",
    "response\n",
    "```\n",
    "\n",
    "### What happens step-by-step (very important)\n",
    "\n",
    "1Ô∏è‚É£ `\"input\"` is embedded\n",
    "2Ô∏è‚É£ Retriever finds top-2 chunks\n",
    "3Ô∏è‚É£ Chunks ‚Üí `{context}`\n",
    "4Ô∏è‚É£ Prompt is formed\n",
    "5Ô∏è‚É£ LLM generates answer\n",
    "\n",
    "---\n",
    "\n",
    "### What `response` contains\n",
    "\n",
    "Usually:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"input\": \"...\",\n",
    "  \"context\": [Document, Document],\n",
    "  \"answer\": \"...\"\n",
    "}\n",
    "```\n",
    "\n",
    "This is **debug-friendly**:\n",
    "\n",
    "* you can inspect retrieved chunks\n",
    "* verify hallucinations\n",
    "* tune `k`\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Ultra-short recap (memorize this)\n",
    "\n",
    "* `as_retriever()` ‚Üí makes vector store usable\n",
    "* `ChatPromptTemplate` ‚Üí defines RAG prompt\n",
    "* `create_stuff_documents_chain` ‚Üí stuffs context\n",
    "* `create_retrieval_chain` ‚Üí full RAG pipeline\n",
    "* `.invoke()` ‚Üí executes everything\n",
    "\n",
    "---\n",
    "\n",
    "## Final question (answer before we proceed)\n",
    "\n",
    "üëâ **Why is this called ‚ÄúTraditional RAG‚Äù and not ‚ÄúConversational RAG‚Äù?**\n",
    "\n",
    "(One sentence is enough. This unlocks the next topic.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48608e2",
   "metadata": {},
   "source": [
    "### Create RAG Chain Alternative - Using LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8703a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables   import RunnablePassthrough, RunnableParallel\n",
    "from langchain_classic.prompts import ChatPromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8395d488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question. \\nIf you don't know the answer based on the context, say you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a custom prompt\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\"\"Use the following context to answer the question. \n",
    "If you don't know the answer based on the context, say you don't know.\n",
    "Provide specific details from the context to support your answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\")\n",
    "custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54e94a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7cbd7a2117f0>, search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7164d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format the output documents for the prompt\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0e64b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. This is supported by the context, which states: \"There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement.\"'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_rcel = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_rcel.invoke(\"What are the three types of machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838e240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7cbd7a2117f0>, search_kwargs={'k': 2})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question. \\nIf you don't know the answer based on the context, say you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x7cbd75b1dbb0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7cbd75b1d1c0>, root_client=<openai.OpenAI object at 0x7cbd75b1d8b0>, root_async_client=<openai.AsyncOpenAI object at 0x7cbd75b1d640>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_rcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "122a833c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7cbd7a2117f0>, search_kwargs={'k': 2})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question. \\nIf you don't know the answer based on the context, say you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x7cbd75b1dbb0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7cbd75b1d1c0>, root_client=<openai.OpenAI object at 0x7cbd75b1d8b0>, root_async_client=<openai.AsyncOpenAI object at 0x7cbd75b1d640>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build the chain ussing LCEL\n",
    "\n",
    "rag_chain_lcel=(\n",
    "    { \n",
    "        \"context\":retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "     }\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8a3db27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context, ML stands for machine learning. It is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_stream = \"What is ML?\"\n",
    "\n",
    "rag_chain_lcel.invoke(question_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb31ea9",
   "metadata": {},
   "source": [
    "### Add New Documents To Existing Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "200572db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x7cbd7a2117f0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b01596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new documents to the existing vector store\n",
    "new_document = \"\"\"\n",
    "Reinforcement Learning in Detail\n",
    "\n",
    "Reinforcement learning (RL) is a type of machine learning where an agent learns to make \n",
    "decisions by interacting with an environment. The agent receives rewards or penalties \n",
    "based on its actions and learns to maximize cumulative reward over time. Key concepts \n",
    "in RL include: states, actions, rewards, policies, and value functions. Popular RL \n",
    "algorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \n",
    "Actor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \n",
    "robotics, and autonomous systems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7479932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts \\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "811c7464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/tmp/tmpr74h95rr/doc_2.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_2.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_2.txt'}, page_content='processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_3.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_3.txt'}, page_content='NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_3.txt'}, page_content='architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_1.txt'}, page_content='Machine Learning Fundamentals'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_1.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement'),\n",
       " Document(metadata={'source': '/tmp/tmpr74h95rr/doc_1.txt'}, page_content='learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a65f0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc_store = Document(\n",
    "    page_content= new_document,\n",
    "    metadata = {\"source\": \"manual_addition\", \"topic\": \"reinforcement_learning\"}\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7cc3fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts \\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.\\n')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce79e32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='Reinforcement Learning in Detail'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='Reinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='in RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chunk = text_splitter.split_documents(\n",
    "    [new_doc_store]\n",
    ")\n",
    "\n",
    "new_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3690fbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14380984-73bf-46f5-9ec3-213fcc95638c',\n",
       " 'dcb044ab-e582-413e-a93e-7bd63baec4fc',\n",
       " '76c1d898-9dd7-44f8-8f8e-6ef1f5798e22']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(new_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5616ee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors now: 12\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total vectors now: {vector_store._collection.count()}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0847062e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['49e93d98-c02d-4303-af2b-93129b1de48f',\n",
       "  '2b399c53-d023-417b-80e7-f1331f7cb5a9',\n",
       "  'c5dd5f81-9537-4639-b251-4dd867c00b05',\n",
       "  'ce0d3cfb-7445-4b0d-81bd-868ba6764660',\n",
       "  '5bb129d2-38d3-4894-b082-3e64f8d523a3',\n",
       "  '29cf2466-321c-47c8-9c50-5548206430da',\n",
       "  '2dc475fa-d442-4fd4-9f3d-282bd352daed',\n",
       "  'af23f568-f75c-4a78-90bb-5672a66dda10',\n",
       "  '861998ee-6bbe-4492-869a-ad187b76a78a',\n",
       "  '14380984-73bf-46f5-9ec3-213fcc95638c',\n",
       "  'dcb044ab-e582-413e-a93e-7bd63baec4fc',\n",
       "  '76c1d898-9dd7-44f8-8f8e-6ef1f5798e22'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Deep Learning and Neural Networks',\n",
       "  'Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language',\n",
       "  'processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.',\n",
       "  'Natural Language Processing (NLP)',\n",
       "  'NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer',\n",
       "  'architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.',\n",
       "  'Machine Learning Fundamentals',\n",
       "  'Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement',\n",
       "  'learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.',\n",
       "  'Reinforcement Learning in Detail',\n",
       "  'Reinforcement learning (RL) is a type of machine learning where an agent learns to make \\ndecisions by interacting with an environment. The agent receives rewards or penalties \\nbased on its actions and learns to maximize cumulative reward over time. Key concepts',\n",
       "  'in RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and \\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), \\nrobotics, and autonomous systems.'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': '/tmp/tmpr74h95rr/doc_2.txt'},\n",
       "  {'source': '/tmp/tmpr74h95rr/doc_2.txt'},\n",
       "  {'source': '/tmp/tmpr74h95rr/doc_2.txt'},\n",
       "  {'source': '/tmp/tmpr74h95rr/doc_3.txt'},\n",
       "  {'source': '/tmp/tmpr74h95rr/doc_3.txt'},\n",
       "  {'source': '/tmp/tmpr74h95rr/doc_3.txt'},\n",
       "  {'source': '/tmp/tmpr74h95rr/doc_1.txt'},\n",
       "  {'source': '/tmp/tmpr74h95rr/doc_1.txt'},\n",
       "  {'source': '/tmp/tmpr74h95rr/doc_1.txt'},\n",
       "  {'source': 'manual_addition', 'topic': 'reinforcement_learning'},\n",
       "  {'source': 'manual_addition', 'topic': 'reinforcement_learning'},\n",
       "  {'source': 'manual_addition', 'topic': 'reinforcement_learning'}]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90dbdb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context mentions that reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment and receives rewards or penalties based on its actions. \n",
      "\n",
      "Based on the context, the key concepts in reinforcement learning are:\n",
      "- Agent: the entity that makes decisions.\n",
      "- Environment: where the agent interacts.\n",
      "- Actions: what the agent does.\n",
      "- Rewards or penalties: feedback received by the agent based on its actions.\n",
      "- Cumulative reward: overall reward the agent learns to maximize over time.\n",
      "\n",
      "These are the key concepts supported by the details in the provided context.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain_rcel.invoke(\"What are the keys concepts in reinforcement learning\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c05cfc",
   "metadata": {},
   "source": [
    "## Conversational Memory in RAG\n",
    "\n",
    "### The Problem\n",
    "- Traditional RAG treats each query independently\n",
    "- Loses context from previous interactions\n",
    "- Cannot resolve pronouns (it, they, that) or follow-up questions\n",
    "- Users must repeat context for each query\n",
    "\n",
    "### The Solution\n",
    "- Query reformulation: Transforms context-dependent questions into standalone queries\n",
    "- Context-aware retrieval: Uses reformulated query to fetch relevant documents\n",
    "- Enables natural dialogue flow without repeating information\n",
    "\n",
    "### Why It Matters\n",
    "Essential for conversational AI where users expect back-and-forth interactions like human conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe694d6",
   "metadata": {},
   "source": [
    "- create_history_aware_retriever: Makes the retriever understand conversation context\n",
    "- MessagesPlaceholder: Placeholder for chat history in prompts\n",
    "- HumanMessage/AIMessage: Structured message types for conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf1bd761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2fc7c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a prompt that includes the chat history\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \n",
    "which might reference context in the chat history, formulate a standalone question \n",
    "which can be understood without the chat history. Do NOT answer the question, \n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "59714f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7cbd7a2117f0>, search_kwargs={'k': 2}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7cbeb785b740>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user question \\nwhich might reference context in the chat history, formulate a standalone question \\nwhich can be understood without the chat history. Do NOT answer the question, \\njust reformulate it if needed and otherwise return it as is.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x7cbd75b1dbb0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7cbd75b1d1c0>, root_client=<openai.OpenAI object at 0x7cbd75b1d8b0>, root_async_client=<openai.AsyncOpenAI object at 0x7cbd75b1d640>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7cbd7a2117f0>, search_kwargs={'k': 2})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create history aware retriever\n",
    "history_aware_retriver = create_history_aware_retriever(\n",
    "    llm,\n",
    "    retriever,\n",
    "    contextualize_q_prompt\n",
    ")\n",
    "\n",
    "history_aware_retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f3d6a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversational RAG chain created!\n"
     ]
    }
   ],
   "source": [
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(\n",
    "    llm,\n",
    "    qa_prompt\n",
    ")\n",
    "\n",
    "# Create conversational RAG chain\n",
    "conversational_rag_chain = create_retrieval_chain(\n",
    "    history_aware_retriver,\n",
    "    question_answer_chain\n",
    ")\n",
    "\n",
    "print(\"Conversational RAG chain created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb202e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is machine learning?\n",
      "A: ML stands for machine learning, a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "#First Question\n",
    "result1 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"What is ML?\"\n",
    "})\n",
    "\n",
    "print(f\"Q: What is machine learning?\")\n",
    "print(f\"A: {result1['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "16df5bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is machine learning', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ML stands for machine learning, a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.extend([\n",
    "    HumanMessage(content=\"What is machine learning\"),\n",
    "    AIMessage(content=result1['answer'])\n",
    "])\n",
    "\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d958f9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='What is machine learning', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='ML stands for machine learning, a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.', additional_kwargs={}, response_metadata={})],\n",
       " 'input': 'What are its main type',\n",
       " 'context': [Document(metadata={'source': '/tmp/tmpr74h95rr/doc_1.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement'),\n",
       "  Document(metadata={'source': '/tmp/tmpr74h95rr/doc_1.txt'}, page_content='Machine Learning Fundamentals')],\n",
       " 'answer': 'The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## follow up question\n",
    "\n",
    "result2 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"What are its main type\"\n",
    "})\n",
    "\n",
    "result2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
